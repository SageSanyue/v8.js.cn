<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><title>V8</title><subtitle>JavaScript V8 引擎</subtitle><link href="https://v8.js.cn/blog.atom" rel="self"/><link href="https://v8.js.cn/"/><updated>2019-07-01T16:45:00+00:00</updated><id>https://v8.js.cn/</id><author><name>Mathias Bynens</name></author><entry><title>Emscripten and the LLVM WebAssembly backend</title><link href="https://v8.js.cn/blog/emscripten-llvm-wasm/"/><updated>2019-07-01T16:45:00+00:00</updated><id>https://v8.js.cn/blog/emscripten-llvm-wasm/</id><author><name>Alon Zakai</name></author><content type="html">&lt;p&gt;WebAssembly is normally compiled from a source language, which means that developers need &lt;em&gt;tools&lt;/em&gt; to use it. Because of that, the V8 team works on relevant open-source projects like &lt;a href=&quot;http://llvm.org/&quot;&gt;LLVM&lt;/a&gt;, &lt;a href=&quot;https://emscripten.org/&quot;&gt;Emscripten&lt;/a&gt;, &lt;a href=&quot;https://github.com/WebAssembly/binaryen/&quot;&gt;Binaryen&lt;/a&gt;, and &lt;a href=&quot;https://github.com/WebAssembly/wabt&quot;&gt;WABT&lt;/a&gt;. This post describes some of the work we’ve been doing on Emscripten and LLVM, which will soon allow Emscripten to switch to the &lt;a href=&quot;https://github.com/llvm/llvm-project/tree/master/llvm/lib/Target/WebAssembly&quot;&gt;LLVM WebAssembly backend&lt;/a&gt; by default — please test it and report any issues!&lt;/p&gt;
&lt;p&gt;The LLVM WebAssembly backend has been an option in Emscripten for some time, as we have been working on the backend in parallel to its integration in Emscripten, and in collaboration with others in the open source WebAssembly tools community. It has now reached the point where the WebAssembly backend beats the old “&lt;a href=&quot;https://github.com/emscripten-core/emscripten-fastcomp/&quot;&gt;fastcomp&lt;/a&gt;” backend on most metrics, and therefore we would like to switch the default to it. This announcement is happening before that, to get as much testing as we can first.&lt;/p&gt;
&lt;p&gt;This is an important upgrade for several exciting reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Much faster linking&lt;/strong&gt;: the LLVM WebAssembly backend together with &lt;a href=&quot;https://lld.llvm.org/WebAssembly.html&quot;&gt;&lt;code&gt;wasm-ld&lt;/code&gt;&lt;/a&gt; has full support for incremental compilation using WebAssembly object files. Fastcomp used LLVM IR in bitcode files, which meant that at link time all the IR would be compiled by LLVM. This was the main reason for slow link times. With WebAssembly object files on the other hand, &lt;code&gt;.o&lt;/code&gt; files contain already-compiled WebAssembly (in a relocatable form that can be linked, much like native linking). As a result the link step can be much, much faster than with fastcomp — we’ll see a real-world measurement below with a 7× speedup!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Faster and smaller code&lt;/strong&gt;: We’ve worked hard on the LLVM WebAssembly backend as well as on the Binaryen optimizer which Emscripten runs after it. The result is that the LLVM WebAssembly backend path now beats fastcomp on both speed and size on most benchmarks we track.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support all LLVM IR&lt;/strong&gt;: Fastcomp could handle the LLVM IR emitted by &lt;code&gt;clang&lt;/code&gt;, but because of its architecture it often failed on other sources, specifically on “legalizing” the IR into types that fastcomp could handle. The LLVM WebAssembly backend on the other hand uses the common LLVM backend infrastructure, so it can handle everything.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New WebAssembly features&lt;/strong&gt;: Fastcomp compiles to asm.js before running &lt;code&gt;asm2wasm&lt;/code&gt;, which means that it is difficult to handle new WebAssembly features like tail calls, exceptions, SIMD, and so forth. The WebAssembly backend is the natural place to work on those, and we are in fact working on all of the features just mentioned!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Faster general updates from upstream&lt;/strong&gt;: Related to the last point, using the upstream WebAssembly backend means we can use very latest LLVM upstream at all times, which means we can get new C++ language features in &lt;code&gt;clang&lt;/code&gt;, new LLVM IR optimizations, etc. as soon as they land.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;testing&quot;&gt;Testing &lt;a class=&quot;bookmark&quot; href=&quot;#testing&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To test the WebAssembly backend, simply use the &lt;a href=&quot;https://github.com/emscripten-core/emsdk&quot;&gt;latest &lt;code&gt;emsdk&lt;/code&gt;&lt;/a&gt; and do&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;emsdk install latest-upstream
emsdk activate latest-upstream
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;“Upstream” here refers to the fact that the LLVM WebAssembly backend is in upstream LLVM, unlike fastcomp. In fact, since it’s in upstream, you don’t need to use the &lt;code&gt;emsdk&lt;/code&gt; if you build plain LLVM+&lt;code&gt;clang&lt;/code&gt; yourself! (To use such a build with Emscripten, just add the path to it in your &lt;code&gt;.emscripten&lt;/code&gt; file.)&lt;/p&gt;
&lt;p&gt;Currently using &lt;code&gt;emsdk [install|activate] latest&lt;/code&gt; still uses fastcomp. There is also “latest-fastcomp” which does the same. When we switch the default backend, we will make “latest” do the same as “latest-upstream”, and at that time “latest-fastcomp” will be the only way to get fastcomp. Fastcomp remains an option while it is still useful; see more notes about this at the end.&lt;/p&gt;
&lt;h2 id=&quot;history&quot;&gt;History &lt;a class=&quot;bookmark&quot; href=&quot;#history&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This will be the &lt;strong&gt;third&lt;/strong&gt; backend in Emscripten, and the &lt;strong&gt;second&lt;/strong&gt; migration. The first backend was written in JavaScript and parsed LLVM IR in text form. This was useful for experimentation back in 2010, but had obvious downsides, including that LLVM’s text format would change and compilation speed wasn’t as fast as we wanted. In 2013 a new backend was written in a fork of LLVM, nicknamed “fastcomp”. It was designed to emit &lt;a href=&quot;https://en.wikipedia.org/wiki/Asm.js&quot;&gt;asm.js&lt;/a&gt;, which the earlier JS backend had been hacked to do (but didn’t do very well). As a result it was a big improvement in code quality and compile times.&lt;/p&gt;
&lt;p&gt;It was also a relatively minor change in Emscripten. While Emscripten is a compiler, the original backend and fastcomp have always been a fairly small part of the project — far more code goes into system libraries, toolchain integration, language bindings, and so forth. So while switching the compiler backend is a dramatic change, it affects just one part of the overall project.&lt;/p&gt;
&lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks &lt;a class=&quot;bookmark&quot; href=&quot;#benchmarks&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;code-size&quot;&gt;Code size &lt;a class=&quot;bookmark&quot; href=&quot;#code-size&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/emscripten-llvm-wasm/size.svg&quot; intrinsicsize=&quot;1133x638&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Code size measurements (lower is better)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;(All sizes here are normalized to fastcomp.) As you can see, the WebAssembly backend’s sizes are almost always smaller! The difference is more noticeable on the smaller microbenchmarks on the left (names in lowercase), where new improvements in system libraries matter more. But there is a code size reduction even on most of the macrobenchmarks on the right (names in UPPERCASE), which are real-world codebases. The one regression on the macrobenchmarks is LZMA, where newer LLVM makes a different inlining decision that ends up unlucky.&lt;/p&gt;
&lt;p&gt;Overall, the macrobenchmarks shrink by an average of &lt;strong&gt;3.7%&lt;/strong&gt;. Not bad for a compiler upgrade! We see similar things on real-world codebases that are not in the test suite, for example, &lt;a href=&quot;https://github.com/kripken/BananaBread/&quot;&gt;BananaBread&lt;/a&gt;, a port of the &lt;a href=&quot;http://cubeengine.com/&quot;&gt;Cube 2 game engine&lt;/a&gt; to the Web, shrinks by over &lt;strong&gt;6%&lt;/strong&gt;, and &lt;a href=&quot;http://www.continuation-labs.com/projects/d3wasm/&quot;&gt;Doom 3 shrinks by&lt;/a&gt; &lt;strong&gt;15%&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;These size improvements (and the speed improvements we’ll discuss next) are due to several factors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLVM’s backend codegen is smart and can do things that simple backends like fastcomp can’t, like &lt;a href=&quot;https://en.wikipedia.org/wiki/Value_numbering&quot;&gt;GVN&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Newer LLVM has better IR optimizations.&lt;/li&gt;
&lt;li&gt;We’ve worked a lot on tuning the Binaryen optimizer on the WebAssembly backend’s output, as mentioned earlier.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;speed&quot;&gt;Speed &lt;a class=&quot;bookmark&quot; href=&quot;#speed&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/emscripten-llvm-wasm/speed.svg&quot; intrinsicsize=&quot;1133x638&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Speed measurements (lower is better)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;(Measurements are on v8.) Among the microbenchmarks, speed is a mixed picture — which is not that surprising, since most of them are dominated by a single function or even loop, so any change to the code Emscripten emits can lead to a lucky or unlucky optimization choice by the VM. Overall, about an equal number of microbenchmarks stay the same as those that improve or those that regress. Looking at the more realistic macrobenchmarks, once more LZMA is an outlier, again because of an unlucky inlining decision as mentioned earlier, but otherwise every single macrobenchmark improves!&lt;/p&gt;
&lt;p&gt;The average change on the macrobenchmarks is a speedup of &lt;strong&gt;3.2%&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&quot;build-time&quot;&gt;Build time &lt;a class=&quot;bookmark&quot; href=&quot;#build-time&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/emscripten-llvm-wasm/build.svg&quot; intrinsicsize=&quot;1133x638&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Compile and link time measurements on BananaBread (lower is better)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Build time changes will vary by project, but here are some example numbers from BananaBread, which is a complete but compact game engine consisting of 112 files and 95,287 lines of code. On the left we have build times for the compile step, that is, compiling source files to object files, using the project’s default &lt;code&gt;-O3&lt;/code&gt; (all times are normalized to fastcomp). As you can see, the compile step takes slightly longer with the WebAssembly backend, which makes sense because we are doing more work at this stage — instead of just compiling source to bitcode as fastcomp does, we also compile the bitcode to WebAssembly.&lt;/p&gt;
&lt;p&gt;Looking on the right, we have the numbers for the link step (also normalized to fastcomp), that is, producing the final executable, here with &lt;code&gt;-O0&lt;/code&gt; which is suitable for an incremental build (for a fully-optimized one, you would probably use &lt;code&gt;-O3&lt;/code&gt; as well, see below). It turns out that the slight increase during the compile step is worth it, because the link is &lt;strong&gt;over 7× faster&lt;/strong&gt;! That’s the real advantage of incremental compilation: most of the link step is just a quick concatenation of object files. And if you change just one source file and rebuild then almost all you need is that fast link step, so you can see this speedup all the time during real-world development.&lt;/p&gt;
&lt;p&gt;As mentioned above, build time changes will vary by project. In a smaller project than BananaBread the link time speedup may be smaller, while on a bigger project it may be larger. Another factor is optimizations: as mentioned above, the test linked with &lt;code&gt;-O0&lt;/code&gt;, but for a release build you’ll want &lt;code&gt;-O3&lt;/code&gt; probably, and in that case Emscripten will invoke the Binaryen optimizer on the final WebAssembly, run &lt;a href=&quot;https://hacks.mozilla.org/2018/01/shrinking-webassembly-and-javascript-code-sizes-in-emscripten/&quot;&gt;meta-dce&lt;/a&gt;, and other useful things for code size and speed. That takes extra time, of course, and it’s worth it for a release build — on BananaBread it shrinks the WebAssembly from 2.65 to 1.84 MB, an improvement of over &lt;strong&gt;30%&lt;/strong&gt; — but for a quick incremental build you can skip that with &lt;code&gt;-O0&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;known-issues&quot;&gt;Known issues &lt;a class=&quot;bookmark&quot; href=&quot;#known-issues&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While the LLVM WebAssembly backend generally wins on both code size and speed, we have seen some exceptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/emscripten-core/emscripten/blob/incoming/tests/fasta.cpp&quot;&gt;Fasta&lt;/a&gt; regresses without &lt;a href=&quot;https://github.com/WebAssembly/nontrapping-float-to-int-conversions&quot;&gt;nontrapping float to int conversions&lt;/a&gt;, a new WebAssembly feature that was not in the WebAssembly MVP. The underlying issue is that in the MVP a float to int conversion will trap if it was out of the range of valid integers. The reasoning was that this is undefined behavior in C anyhow, and easy for VMs to implement. However, this turned out to be a poor match for how LLVM compiles float to int conversions, with the result that extra guards are needed, adding code size and overhead. The newer non-trapping operations avoid that, but may not be present in all browsers yet. You can use them by compiling source files with &lt;code&gt;-mnontrapping-fptoint&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The LLVM WebAssembly backend is not just a different backend than fastcomp but also uses a much newer LLVM. Newer LLVM may make different inlining decisions, which (like all inlining decisions in the absence of profile-guided optimization) are heuristic-driven and may end up helping or hurting. A specific example we mentioned earlier is in the LZMA benchmark where newer LLVM ends up inling a function 5 times in a way that ends up just causing harm. If you encounter this in your own projects, you can selectively build certain source files with &lt;code&gt;-Os&lt;/code&gt; to focus on code size, use &lt;code&gt;__attribute__((noinline))&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There may be more issues we are not aware of that should be optimized — please let us know if you find anything!&lt;/p&gt;
&lt;h2 id=&quot;other-changes&quot;&gt;Other changes &lt;a class=&quot;bookmark&quot; href=&quot;#other-changes&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;There are a small number of Emscripten features that are tied to fastcomp and/or to asm.js, which means that they can’t work out of the box with the WebAssembly backend, and so we have been working on alternatives.&lt;/p&gt;
&lt;h3 id=&quot;javascript-output&quot;&gt;JavaScript output &lt;a class=&quot;bookmark&quot; href=&quot;#javascript-output&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An option for non-WebAssembly output is still important in some cases — although all major browsers have had WebAssembly support for some time, there is still a long tail of old machines, old phones, etc. that don’t have WebAssembly support. Also, as WebAssembly adds new features some form of this issue will stay relevant. Compiling to JS is a way to guarantee you can reach everyone, even if the build isn’t as small or fast as WebAssembly would be. With fastcomp we simply used the asm.js output for this directly, but with the WebAssembly backend obviously something else is needed. We are using Binaryen’s &lt;a href=&quot;https://github.com/WebAssembly/binaryen#wasm2js&quot;&gt;&lt;code&gt;wasm2js&lt;/code&gt;&lt;/a&gt; for that purpose, which as the name suggests compiles WebAssembly to JS.&lt;/p&gt;
&lt;p&gt;This probably warrants a full blog post, but in brief, a key design decision here is that there is no point to supporting asm.js anymore. asm.js can run much faster than general JS, but it turns out that practically all browsers that support asm.js AOT optimizations also support WebAssembly anyhow (in fact, Chrome optimizes asm.js by converting it to WebAssembly internally!). So when we talk about a JS fallback option, it may as well not use asm.js; in fact it’s simpler, allows us to support more features in WebAssembly, and also results in significantly smaller JS as well! Therefore &lt;code&gt;wasm2js&lt;/code&gt; does not target asm.js.&lt;/p&gt;
&lt;p&gt;However, a side effect of that design is that if you test an asm.js build from fastcomp compared to a JS build with the WebAssembly backend then the asm.js may be much faster — if you test in a modern browser with asm.js AOT optimizations. That is probably the case for your own browser, but not the browsers that would actually need the non-WebAssembly option! For a proper comparison, you should use a browser without asm.js optimizations or with them disabled. If the &lt;code&gt;wasm2js&lt;/code&gt; output is still slower, please let us know!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wasm2js&lt;/code&gt; is missing some less-used features like dynamic linking and pthreads, but most code should work already, and it’s been carefully fuzzed. To test the JS output, simply build with &lt;code&gt;-s WASM=0&lt;/code&gt; to disable WebAssembly. &lt;code&gt;emcc&lt;/code&gt; then runs &lt;code&gt;wasm2js&lt;/code&gt; for you, and if this is an optimized build it runs various useful optimizations as well.&lt;/p&gt;
&lt;h3 id=&quot;other-things-you-may-notice&quot;&gt;Other things you may notice &lt;a class=&quot;bookmark&quot; href=&quot;#other-things-you-may-notice&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;https://github.com/emscripten-core/emscripten/wiki/Asyncify&quot;&gt;Asyncify&lt;/a&gt; and &lt;a href=&quot;https://github.com/emscripten-core/emscripten/wiki/Emterpreter&quot;&gt;Emterpreter&lt;/a&gt; options only work in fastcomp. A replacement &lt;a href=&quot;https://github.com/WebAssembly/binaryen/pull/2172&quot;&gt;is&lt;/a&gt; &lt;a href=&quot;https://github.com/WebAssembly/binaryen/pull/2173&quot;&gt;being&lt;/a&gt; &lt;a href=&quot;https://github.com/emscripten-core/emscripten/pull/8808&quot;&gt;worked&lt;/a&gt; &lt;a href=&quot;https://github.com/emscripten-core/emscripten/issues/8561&quot;&gt;on&lt;/a&gt;. We expect this to eventually be an improvement on the previous options.&lt;/li&gt;
&lt;li&gt;Pre-built libraries must be rebuilt: if you have some &lt;code&gt;library.bc&lt;/code&gt; that was built with fastcomp, then you’ll need to rebuild it from source using newer Emscripten. This has always been the case when fastcomp upgraded LLVM to a new version which changed the bitcode format, and the change now (to WebAssembly object files instead of bitcode) has the same effect.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a class=&quot;bookmark&quot; href=&quot;#conclusion&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Our main goal right now is to fix any bugs related to this change. Please test and file issues!&lt;/p&gt;
&lt;p&gt;After things are stable, we’ll switch the default compiler backend to the upstream WebAssembly backend. Fastcomp will remain an option, as mentioned earlier.&lt;/p&gt;
&lt;p&gt;We would like to eventually remove fastcomp entirely. Doing so would remove a significant maintenance burden, allow us to focus more on new features in the WebAssembly backend, accelerate general improvements in Emscripten, and other good things. Please let us know how testing goes on your codebases so we can start to plan a timeline for fastcomp’s removal.&lt;/p&gt;
&lt;h3 id=&quot;thank-you&quot;&gt;Thank you &lt;a class=&quot;bookmark&quot; href=&quot;#thank-you&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Thanks to everyone involved in the development of the LLVM WebAssembly backend, &lt;code&gt;wasm-ld&lt;/code&gt;, Binaryen, Emscripten, and the other things mentioned in this post! A partial list of those awesome people is: aardappel, aheejin, alexcrichton, dschuff, jfbastien, jgravelle, nwilson, sbc100, sunfish, tlively, yurydelendik.&lt;/p&gt;
</content></entry><entry><title>JavaScript 的性能开销(2019版)</title><link href="https://v8.js.cn/blog/cost-of-javascript-2019/"/><updated>2019-06-25T00:00:00+00:00</updated><id>https://v8.js.cn/blog/cost-of-javascript-2019/</id><author><name>Addy Osmani (@addyosmani), JavaScript Janitor</name></author><content type="html">&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：如果您更喜欢观看演示文稿，请欣赏下面的视频！如果没有，请跳过视频并继续阅读。&lt;/p&gt;
&lt;/div&gt;
&lt;figure&gt;
  &lt;div class=&quot;video video-16:9&quot;&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/X9eRLElSW1c&quot; allow=&quot;picture-in-picture&quot; allowfullscreen=&quot;&quot; loading=&quot;lazy&quot;&gt;&lt;/iframe&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=X9eRLElSW1c&quot;&gt;“The cost of JavaScript”&lt;/a&gt; as presented by Addy Osmani at #PerfMatters Conference 2019.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;过去几年中，&lt;a href=&quot;https://medium.com/@addyosmani/the-cost-of-javascript-in-2018-7d8950fbb5d4&quot;&gt;JavaScript 性能&lt;/a&gt;的大幅改进很大程度上依赖于浏览器解析和编译 JavaScript 的速度。&lt;strong&gt;在 2019 年，处理 JavaScript 的主要性能损耗在于下载和 CPU 执行时间&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;浏览器主线程忙于执行 JavaScript 时，用户交互会被延迟，因此脚本执行时间和网络上的瓶颈优化尤其重要。&lt;/p&gt;
&lt;h2 id=&quot;guidance&quot;&gt;可行的高级指南 &lt;a class=&quot;bookmark&quot; href=&quot;#guidance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这对于 web 开发者意味着什么？解析和编译的性能损耗&lt;strong&gt;不再像从前我们认为的那样慢&lt;/strong&gt;。我们需要关注三点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;提升下载速度&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;减小 JavaScript 包的体积，尤其是在移动设备上。更小的包可以提升下载速度，带来更低的内存占用，并减少 CPU 性能损耗。&lt;/li&gt;
&lt;li&gt;避免把代码打包成一个大文件。如果一个包超过 50–100 kB，把它分割成多个更小的包。（由于 HTTP/2 的多路复用特性，多个请求和响应可以同时到达，从而减少额外请求的负载。）&lt;/li&gt;
&lt;li&gt;由于移动设备上的网络速度，你应该减少网络传输，而且也需要维持更低的内存使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提升执行速度&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;避免使主线程忙碌的&lt;a href=&quot;https://w3c.github.io/longtasks/&quot;&gt;长任务(Long Tasks)&lt;/a&gt;，使页面快点进行可交互态。脚本执行时间目前成为了一个主要的性能损耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;避免大型内联脚&lt;/strong&gt; 因为它们也会在主线程中解析和编译）。一个不错的规定是：如果脚本超过 1KB，就不要将其内联（外部脚本的&lt;a href=&quot;https://v8.js.cn/blog/code-caching-for-devs&quot;&gt;字节码缓存&lt;/a&gt;要求最小为 1KB 也是一个原因）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;download-execute&quot;&gt;为何优化下载和执行时间很重要？ &lt;a class=&quot;bookmark&quot; href=&quot;#download-execute&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;为何优化下载和执行时间很重要？下载时间在低端网络环境下很关键。尽管 4G（甚至 5G）在全球范围快速发展，我们&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/NetworkInformation/effectiveType&quot;&gt;实际感受到的网络速度&lt;/a&gt;和宣传并不一致，很多时候感觉就像 3G（甚至更差）。&lt;/p&gt;
&lt;p&gt;JavaScript 执行时间在使用低端 CPU 的手机上很重要。由于 CPU、GPU 和散热上的差异，不同手机上性能差异非常大。这会影响到 JavaScript 的性能，因为 JavaScript 的执行是 CPU 密集型任务。&lt;/p&gt;
&lt;p&gt;实际上，像 Chrome 这样的浏览器上的页面加载总时间，有多达 30% 的时间花在 JavaScript 执行上。下面是一个任务负载（Reddit.com）很典型的网站在高端桌面设备上的页面加载，&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/reddit-js-processing.svg&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;V8 中的 JavaScript 处理占用了页面加载时间的 10-30%。&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;移动设备上，中端机（Moto G4）的 JavaScript 执行时间是高端机（Pixel 3）的 3 到 4 倍，低端机（不到 100 刀的 Alcatel 1X）上有超过 6 倍的性能差异：&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/reddit-js-processing-devices.svg&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Reddit 在不同设备类型上（低端、中端和高端）的 JavaScript 性能损耗&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; Reddit 在桌面端和移动端的体验完全不同，因此 MacBook Pro 上的结果并不能和其他设备上的结果直接做比较。&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;当你尝试优化 JavaScript 执行时间，注意关注&lt;a href=&quot;https://web.dev/long-tasks-devtools/&quot;&gt;长任务&lt;/a&gt;，它可能长期独占 UI 线程。这些任务会阻塞执行关键任务，即便页面看起来已经加载完成。把长任务拆分成多个小任务。通过代码分割和指定加载优先级，可以提升页面可交互速度，并且有希望降低输入延迟。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/long-tasks.png&quot; srcset=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/long-tasks@2x.png 2x&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;长任务独占主线程，应该拆分它们。&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;v8-improvements&quot;&gt;V8 在提升解析编译速度上做了什么？ &lt;a class=&quot;bookmark&quot; href=&quot;#v8-improvements&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Chrome 60+ 上，V8 对于初始 JavaScript 的解析速度提升了 2 倍。与此同时， 由于 Chrome 上的其他并行优化，初始解析和编译的性能损耗更少了。&lt;/p&gt;
&lt;p&gt;V8 减少了主线程上的解析编译任务，平均减少了 40%（比如 Facebook 上是 46%，Pinterest 上是 62%）,最高减少了 81%（YouTube），这得益于将解析编译任务搬到了 worker 线程上。这对于流式解析/编译是一个补充。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/chrome-js-parse-times.svg&quot; intrinsicsize=&quot;1280x836&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;不同 V8 版本上的解析时间&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;下图形象呈现了不同 Chrome V8 版本上 CPU 解析时间。Chrome 61 解析 Facebook 的 JS 花了相同的时间，Chrome 75 现在解析 Facebook 的时间是 Twitter 的 6 倍。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/js-parse-times-websites.svg&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Chrome 61 解析 Facebook 的 JS 时间，Chrome 75 可以同时解析 Facebook 和 6次 Twitter 的 JS。&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;我们来研究下这些释放出来的改变。长话短说，流式解析和 worker 线程编译脚本，这意味着：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;V8 可以解析编译 JavaScript 时不阻塞主线程。&lt;/li&gt;
&lt;li&gt;流式解析始于整个 HTML 解析器遇到 &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; 标签。对于阻塞解析的脚本，HTML 解析器会暂停，而异步脚本会继续执行。&lt;/li&gt;
&lt;li&gt;对于大多数真实世界的网络连接速度，V8 解析比下载快，因此 V8 在脚本下载完后很快就完成了解析编译。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;稍微解释下...很老的 Chrome 上会在完整下载完脚本后才开始解析，这很直接但并没有完全利用好 CPU。Chrome 41 和 68 之间的版本上，Chrome 在下载一开始就在一个独立线程上解析 async 和 defer 的脚本。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/script-streaming-1.svg&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;页面上的脚本被分割成多个块。只要代码块超过 30KB，V8 就会开始流式解析。&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Chrome 71 上，我们开始做一个基于任务的调整，调度器可以一次解析多个 async/defer 脚本。这一改变的影响是，主线程解析时间减少 20%，在真实网站上，带来超过 2% 的 TTI/FID 提升。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;译者注：FID(First Input Delay)，第一输入延迟（FID）测量用户首次与您的站点交互时的时间（即，当他们单击链接，点击按钮或使用自定义的 JavaScript 驱动控件时）到浏览器实际能够的时间回应这种互动。交互时间（TTI）是衡量应用加载所需时间并能够快速响应用户交互的指标。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/script-streaming-2.svg&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Chrome 71 moved to a task-based setup where the scheduler could parse multiple async/deferred scripts at once.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Chrome 72 上，我们转向使用流式解析作为主要解析方式：现在一般异步的脚本都以这种方式解析（内联脚本除外）。我们也停止了废除基于任务的解析，如果主线程需要的话，因为那样只是在做不必要的重复工作。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://v8.js.cn/blog/v8-release-75#script-streaming-directly-from-network&quot;&gt;早期版本的 Chrome&lt;/a&gt; 支持流式解析和编译，来自网络的脚本源数据必须先到达 Chrome 的主线程，然后才会转发给流处理器。&lt;/p&gt;
&lt;p&gt;这常会造成流式解析器等待早已下载完成但还没有被转发到流任务的数据，因为它被主线程上的其他任务（比如 HTML 解析，布局或者 JavaScript 执行）所阻塞。&lt;/p&gt;
&lt;p&gt;我们现在正在尝试开始对预加载进行解析，而主线程弹跳会事先对此形成阻塞。&lt;/p&gt;
&lt;p&gt;Leszek Swirski 的 BlinkOn 演示呈现了更多细节：&lt;/p&gt;
&lt;figure&gt;
  &lt;div class=&quot;video video-16:9&quot;&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/D1UJgiG4_NI&quot; allow=&quot;picture-in-picture&quot; allowfullscreen=&quot;&quot; loading=&quot;lazy&quot;&gt;&lt;/iframe&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=D1UJgiG4_NI&quot;&gt;“Parsing JavaScript in zero* time”&lt;/a&gt; as presented by Leszek Swirski at BlinkOn 10.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;how-do-these-changes-reflect-what-you-see-in-devtools%3F&quot;&gt;DevTools 上如何查看这些改变？ &lt;a class=&quot;bookmark&quot; href=&quot;#how-do-these-changes-reflect-what-you-see-in-devtools%3F&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;除了上述之外，&lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=939275&quot;&gt;DevTools 有个问题&lt;/a&gt;，它暗中使用了 CPU，这会影响到整个解析任务的呈现。然而，解析器解析数据时就会阻塞（它需要在主线程上运行）。自从我们从一个单一的流处理线程中移动到流任务中，这一点就变成更为明显了。下面是你在 Chrome 69 中经常会看到的：&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/devtools-69.png&quot; srcset=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/devtools-69@2x.png 2x&quot; intrinsicsize=&quot;931x98&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;The DevTools issue that rendered the entire parser task in a way that hints that it’s using CPU (full block)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;上图中的“解析脚本”任务花了 1.08 秒。而解析 JavaScript 其实并不慢！多数时间里除了等待数据通过主线程之外什么都不做。&lt;/p&gt;
&lt;p&gt;Chrome 76 的表现大不相同：&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/devtools-76.png&quot; srcset=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/devtools-76@2x.png 2x&quot; intrinsicsize=&quot;922x441&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Chrome 76 上，解析脚本被拆分成多个更小的流式任务。&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;通常，DevTools 性能面板很适合用来查看页面上发生的行为。对于更详细的 V8 特定指标，比如 JavaScript 解析编译时间，我们推荐&lt;a href=&quot;https://v8.js.cn/docs/rcs&quot;&gt;使用带有运行时调用统计(RCS)的 Chrome Tracing&lt;/a&gt;。RCS 结果中，&lt;code&gt;Parse-Background&lt;/code&gt; 和 &lt;code&gt;Compile-Background&lt;/code&gt; 代表主线程之外解析和编译 JavaScript 花费的时间，然而 &lt;code&gt;Parse&lt;/code&gt; 和 &lt;code&gt;Compile&lt;/code&gt; 记录了主线程的指标。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/rcs.png&quot; srcset=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/rcs@2x.png 2x&quot; intrinsicsize=&quot;848x526&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;impact&quot;&gt;这些改变的真实影响？ &lt;a class=&quot;bookmark&quot; href=&quot;#impact&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;来看一些真实网站的例子和脚本流式解析如何应用。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/reddit-main-thread.svg&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;在 MacBook Pro 上，主线程和 workder 线程解析编译 Reddit 的 JS 所花的时间。&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Reddit.com 有多个 100 KB+ 的代码包，这些包被包装在引起主线程大量&lt;a href=&quot;https://v8.js.cn/blog/preparser&quot;&gt;懒编译&lt;/a&gt;的外部函数中。在上图中，由于主线程忙碌会延迟可交互时间，其运行时间至关重要。Reddit 花了多数时间在主线程上，Work/Background 线程的利用率很低。&lt;/p&gt;
&lt;p&gt;这得益于将大包分割成多个小包（比如每个 50KB），以达到最大并行化，从而每个包都可以被独立地流式解析编译，减轻主线程在启动阶段的压力。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/facebook-main-thread.svg&quot; intrinsicsize=&quot;1280x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Facebook 在 Macbook Pro 上的主线程和 worker 线程解析编译时间对比&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;再来看看 Facebook.com。Facebook通过 292 个请求加载了 6MB 压缩后的 JS，其中有些是异步的，有些是预加载的，还有些的加载优先级较低。它们很多 JavaScript 的粒度都非常小 - 这对 Background/Worker 线程上的整体并行化很有用，因为这些小的 JavaScript 可以同时被流式解析编译。&lt;/p&gt;
&lt;p&gt;注意，你可能不是 Facebook，很可能没有一个类似 Facebook 或者 Gmail 这样的长寿应用，在桌面端，它们放如此多的 JavaScript 是无可非议的。然而，一般来说，应该让你的包的粒度较粗，并且按需加载。&lt;/p&gt;
&lt;p&gt;尽管多数 JavaScript 解析编译任务可以在 background 线程中以流的形式完成，但是某些任务仍然必须要在主线程中进行。当主线程忙碌时，页面不能响应用户输入。注意关注下载执行代码对你的用户体验造成的影响。&lt;/p&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 当下，不是所有的 JavaScript 引擎和浏览器都实现了 script streaming 来优化加载。但我们相信大家为了优秀用户体验会加入这项优化的。&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&quot;json&quot;&gt;解析 JSON 的性能损耗 &lt;a class=&quot;bookmark&quot; href=&quot;#json&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;由于 JSON 语法比 JavaScript 语法简单得多，解析 JSON 也会更快。这一点可以用于提升 web 应用的启动性能，我们可以使用类似 JSON 的对象字面量配置（比如内联 Redux store）。不要使用 JavaScript 对象字面量来内联数据，比如这样：&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; foo&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; bar&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1337&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// 🐌&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…它可以被表示成字符串化的 JSON 格式，运行时会变成解析后的 JSON:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token constant&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;{&quot;foo&quot;:42,&quot;bar&quot;:1337}&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// 🚀&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;若 JSON 字符串只被执行一次，尤其是在冷启动阶段，&lt;code&gt;JSON.parse&lt;/code&gt; 方法相比 JavaScript 对象字面量会快得多。在大于 10 KB 的对象上使用这个技巧的效果更佳 - 但在实际应用前，还是先要测试下真实效果。&lt;/p&gt;
&lt;p&gt;在大型数据上使用普通对象字面量还有个风险：它们可能被解析&lt;strong&gt;两次&lt;/strong&gt;！&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一次发生于字面量预解析阶段。&lt;/li&gt;
&lt;li&gt;第二次发生于字面量懒解析阶段。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一次解析无法避免。幸运地，第二次可以通过将对象字面量放在顶层来避免，或者放在 &lt;a href=&quot;https://v8.js.cn/blog/preparser#pife&quot;&gt;PIFE&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;repeat-visits&quot;&gt;关于重复访问上的解析/编译？ &lt;a class=&quot;bookmark&quot; href=&quot;#repeat-visits&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;V8 的字节码缓存优化大有帮助。当首次请求 JavaScript，Chrome 下载然后将其交给 V8 编译。Chrome 也会将文件存进浏览器的磁盘缓存中。当 JS 文件再次请求，Chrome 从浏览器缓存中将其取出，并再次将其交给 V8 编译。这个时候，编译后代码是序列化后的，会作为元数据被添加到缓存的脚本文件上。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/code-caching.png&quot; srcset=&quot;https://v8.js.cn/_img/cost-of-javascript-2019/code-caching@2x.png 2x&quot; intrinsicsize=&quot;1431x774&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;V8 中的字节码缓存工作示意图&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;第三次，Chrome 将文件和文件元数据从缓存中取出，一起交给 V8 处理。V8 对元数据作反序列化，这样可以跳过编译。字节码缓存会在 72 小时内的前两次访问生效。配合使用 service worker 来缓存 JavaScript 代码，Chrome 的字节码缓存效果更佳。你可以在给开发者讲的&lt;a href=&quot;https://v8.js.cn/blog/code-caching-for-devs&quot;&gt;字节码缓存&lt;/a&gt;这篇文章中了解到更多细节。&lt;/p&gt;
&lt;h2 id=&quot;conclusions&quot;&gt;结论 &lt;a class=&quot;bookmark&quot; href=&quot;#conclusions&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;2019 年，下载和执行时间是加载 JavaScript 的主要瓶颈。首屏展示内容里使用异步的（内联）JavaScript的小型包，页面剩下部分使用延迟（deferred）加载的 JavaScript。分解大型包，实现代码按需加载。这样可以最大化 V8 中的并行解析。&lt;/p&gt;
&lt;p&gt;移动设备上，考虑到网络、内存使用和低端 CPU 上的执行时间，你应该传输更少的 JavaScript。平衡可缓存性和延迟，实现在主线程之外解析编译任务数量的最大化。&lt;/p&gt;
&lt;h2 id=&quot;further-reading&quot;&gt;进一步阅读 &lt;a class=&quot;bookmark&quot; href=&quot;#further-reading&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://v8.js.cn/blog/scanner&quot;&gt;Blazingly fast parsing, part 1: optimizing the scanner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://v8.js.cn/blog/preparser&quot;&gt;Blazingly fast parsing, part 2: lazy parsing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><title>V8 release v7.6</title><link href="https://v8.js.cn/blog/v8-release-76/"/><updated>2019-06-19T16:45:00+00:00</updated><id>https://v8.js.cn/blog/v8-release-76/</id><author><name>Adam Klein</name></author><content type="html">&lt;p&gt;Every six weeks, we create a new branch of V8 as part of our &lt;a href=&quot;https://v8.js.cn/docs/release-process&quot;&gt;release process&lt;/a&gt;. Each version is branched from V8’s Git master immediately before a Chrome Beta milestone. Today we’re pleased to announce our newest branch, &lt;a href=&quot;https://chromium.googlesource.com/v8/v8.git/+log/branch-heads/7.6&quot;&gt;V8 version 7.6&lt;/a&gt;, which is in beta until its release in coordination with Chrome 76 Stable in several weeks. V8 v7.6 is filled with all sorts of developer-facing goodies. This post provides a preview of some of the highlights in anticipation of the release.&lt;/p&gt;
&lt;h2 id=&quot;performance&quot;&gt;Performance (size &amp;amp; speed) &lt;a class=&quot;bookmark&quot; href=&quot;#performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;json.parse-improvements&quot;&gt;&lt;code&gt;JSON.parse&lt;/code&gt; improvements &lt;a class=&quot;bookmark&quot; href=&quot;#json.parse-improvements&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In modern JavaScript applications, JSON is commonly used as a format to communicate structured data. By speeding up JSON parsing, we can reduce the latency of this communication. In V8 v7.6, we’ve overhauled our JSON parser to be much faster at scanning and parsing JSON. This results in up to 2.7× faster parsing of data served by popular web pages.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-76/json-parsing.svg&quot; intrinsicsize=&quot;600x371&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Chart showing improved performance of &lt;code&gt;JSON.parse&lt;/code&gt; on a variety of websites&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Up to V8 v7.5, the JSON parser was a recursive parser that would use native stack space relative to the nesting depth of the incoming JSON data. This meant we could run out of stack for very deeply nested JSON data. V8 v7.6 switches to an iterative parser that manages its own stack, which is limited only by available memory.&lt;/p&gt;
&lt;p&gt;The new JSON parser is also more memory-efficient. By buffering properties before we create the final object we can now decide how to allocate the result in an optimal way. For objects with named properties we allocate objects with the exact amount of space needed for the named properties in the incoming JSON data (up to 128 named properties). In case JSON objects contain indexed property names, we allocate an elements backing store that uses the minimal amount of space; either a flat array or a dictionary. JSON arrays are now parsed to an array that exactly fits the number of elements in the input data.&lt;/p&gt;
&lt;h3 id=&quot;frozen%2Fsealed-array-improvements&quot;&gt;Frozen/sealed array improvements &lt;a class=&quot;bookmark&quot; href=&quot;#frozen%2Fsealed-array-improvements&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Performance of calls on frozen or sealed arrays (and array-like objects) received numerous improvements. V8 v7.6 boosts the following JavaScript coding patterns, where &lt;code&gt;frozen&lt;/code&gt; is a frozen or sealed array or array-like object:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;frozen.indexOf(v)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frozen.includes(v)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;spread calls such as &lt;code&gt;fn(...frozen)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;spread calls with a nested array spread such as &lt;code&gt;fn(...[...frozen])&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;apply calls with array spread such as &lt;code&gt;fn.apply(this, [...frozen])&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The chart below shows the improvements.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-76/frozen-sealed-elements.svg&quot; intrinsicsize=&quot;660x408&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Chart showing performance boost on a variety of array operations&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;https://bit.ly/fast-frozen-sealed-elements-in-v8&quot;&gt;See the “fast frozen &amp;amp; sealed elements in V8” design doc&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h3 id=&quot;unicode-string-handling&quot;&gt;Unicode string handling &lt;a class=&quot;bookmark&quot; href=&quot;#unicode-string-handling&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An optimization when &lt;a href=&quot;https://chromium.googlesource.com/v8/v8/+/734c1456d942a03d79aab4b3b0e57afbc803ceea&quot;&gt;converting strings to Unicode&lt;/a&gt; resulted in a significant speed-up for calls such as &lt;code&gt;String#localeCompare&lt;/code&gt;, &lt;code&gt;String#normalize&lt;/code&gt;, and some of the &lt;code&gt;Intl&lt;/code&gt; APIs. For example, this change resulted in around 2× the raw throughput of &lt;code&gt;String#localeCompare&lt;/code&gt; for one-byte strings.&lt;/p&gt;
&lt;h2 id=&quot;javascript-language-features&quot;&gt;JavaScript language features &lt;a class=&quot;bookmark&quot; href=&quot;#javascript-language-features&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;promise.allsettled&quot;&gt;&lt;code&gt;Promise.allSettled&lt;/code&gt; &lt;a class=&quot;bookmark&quot; href=&quot;#promise.allsettled&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://v8.js.cn/features/promise-combinators#promise.allsettled&quot;&gt;&lt;code&gt;Promise.allSettled(promises)&lt;/code&gt;&lt;/a&gt; provides a signal when all the input promises are &lt;em&gt;settled&lt;/em&gt;, which means they’re either &lt;em&gt;fulfilled&lt;/em&gt; or &lt;em&gt;rejected&lt;/em&gt;. This is useful in cases where you don’t care about the state of the promise, you just want to know when the work is done, regardless of whether it was successful. &lt;a href=&quot;https://v8.js.cn/features/promise-combinators&quot;&gt;Our explainer on promise combinators&lt;/a&gt; has more details and includes an example.&lt;/p&gt;
&lt;h3 id=&quot;localized-bigint&quot;&gt;Improved &lt;code&gt;BigInt&lt;/code&gt; support &lt;a class=&quot;bookmark&quot; href=&quot;#localized-bigint&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://v8.js.cn/features/bigint&quot;&gt;&lt;code&gt;BigInt&lt;/code&gt;&lt;/a&gt; now has better API support in the language. You can now format a &lt;code&gt;BigInt&lt;/code&gt; in a locale-aware manner by using the &lt;code&gt;toLocaleString&lt;/code&gt; method. This works just like it does for regular numbers:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token number&quot;&gt;12345678901234567890n&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toLocaleString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;en&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// 🐌&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;12,345,678,901,234,567,890&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token number&quot;&gt;12345678901234567890n&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toLocaleString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;de&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// 🐌&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;12.345.678.901.234.567.890&#39;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you plan on formatting multiple numbers or &lt;code&gt;BigInt&lt;/code&gt;s using the same locale, it’s more efficient to use the &lt;code&gt;Intl.NumberFormat&lt;/code&gt; API, which now supports &lt;code&gt;BigInt&lt;/code&gt;s in its &lt;code&gt;format&lt;/code&gt; and &lt;code&gt;formatToParts&lt;/code&gt; methods. This way, you can create a single re-usable formatter instance.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; nf &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Intl&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;NumberFormat&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;fr&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;nf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;12345678901234567890n&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// 🚀&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;12 345 678 901 234 567 890&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;nf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;formatToParts&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;123456n&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// 🚀&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → [&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { type: &#39;integer&#39;, value: &#39;123&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { type: &#39;group&#39;, value: &#39; &#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { type: &#39;integer&#39;, value: &#39;456&#39; }&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → ]&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;intl-datetimeformat&quot;&gt;&lt;code&gt;Intl.DateTimeFormat&lt;/code&gt; improvements &lt;a class=&quot;bookmark&quot; href=&quot;#intl-datetimeformat&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Apps commonly display date intervals or date ranges to show the span of an event, such as a hotel reservation, the billing period of a service, or a music festival. The &lt;code&gt;Intl.DateTimeFormat&lt;/code&gt; API now supports &lt;code&gt;formatRange&lt;/code&gt; and &lt;code&gt;formatRangeToParts&lt;/code&gt; methods to conveniently format date ranges in a locale-specific manner.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; start &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;2019-05-07T09:20:00&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;May 7, 2019&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; end &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;2019-05-09T16:00:00&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;May 9, 2019&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; fmt &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Intl&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;DateTimeFormat&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;en&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  year&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;numeric&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  month&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;long&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  day&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;numeric&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; output &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; fmt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;formatRange&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;start&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; end&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;May 7 – 9, 2019&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; parts &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; fmt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;formatRangeToParts&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;start&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; end&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → [&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { &#39;type&#39;: &#39;month&#39;,   &#39;value&#39;: &#39;May&#39;,  &#39;source&#39;: &#39;shared&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { &#39;type&#39;: &#39;literal&#39;, &#39;value&#39;: &#39; &#39;,    &#39;source&#39;: &#39;shared&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { &#39;type&#39;: &#39;day&#39;,     &#39;value&#39;: &#39;7&#39;,    &#39;source&#39;: &#39;startRange&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { &#39;type&#39;: &#39;literal&#39;, &#39;value&#39;: &#39; – &#39;,  &#39;source&#39;: &#39;shared&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { &#39;type&#39;: &#39;day&#39;,     &#39;value&#39;: &#39;9&#39;,    &#39;source&#39;: &#39;endRange&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { &#39;type&#39;: &#39;literal&#39;, &#39;value&#39;: &#39;, &#39;,   &#39;source&#39;: &#39;shared&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// →   { &#39;type&#39;: &#39;year&#39;,    &#39;value&#39;: &#39;2019&#39;, &#39;source&#39;: &#39;shared&#39; },&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → ]&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additionally, the &lt;code&gt;format&lt;/code&gt;, &lt;code&gt;formatToParts&lt;/code&gt;, and &lt;code&gt;formatRangeToParts&lt;/code&gt; methods now support the new &lt;code&gt;timeStyle&lt;/code&gt; and &lt;code&gt;dateStyle&lt;/code&gt; options:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; dtf &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Intl&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;DateTimeFormat&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;de&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  timeStyle&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;medium&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  dateStyle&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&#39;short&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;dtf&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Date&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// → &#39;19.06.19, 13:33:37&#39;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;native-stack-walking&quot;&gt;Native stack walking &lt;a class=&quot;bookmark&quot; href=&quot;#native-stack-walking&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While V8 can walk its own call stack (e.g. when debugging or profiling in the DevTools), the Windows operating system was unable to walk a call stack that contains code generated by TurboFan when running on the x64 architecture. This could cause &lt;em&gt;broken stacks&lt;/em&gt; when using native debuggers or ETW sampling to analyze processes that use V8. A recent change enables V8 to &lt;a href=&quot;https://chromium.googlesource.com/v8/v8/+/3cda21de77d098a612eadf44d504b188a599c5f0&quot;&gt;register the necessary metadata&lt;/a&gt; for Windows to be able to walk these stacks on x64, and in v7.6 this is enabled by default.&lt;/p&gt;
&lt;h2 id=&quot;v8-api&quot;&gt;V8 API &lt;a class=&quot;bookmark&quot; href=&quot;#v8-api&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Please use &lt;code&gt;git log branch-heads/7.5..branch-heads/7.6 include/v8.h&lt;/code&gt; to get a list of the API changes.&lt;/p&gt;
&lt;p&gt;Developers with an &lt;a href=&quot;https://v8.js.cn/docs/source-code#using-git&quot;&gt;active V8 checkout&lt;/a&gt; can use &lt;code&gt;git checkout -b 7.6 -t branch-heads/7.6&lt;/code&gt; to experiment with the new features in V8 v7.6. Alternatively you can &lt;a href=&quot;https://www.google.com/chrome/browser/beta.html&quot;&gt;subscribe to Chrome’s Beta channel&lt;/a&gt; and try the new features out yourself soon.&lt;/p&gt;
</content></entry><entry><title>Code caching for WebAssembly developers</title><link href="https://v8.js.cn/blog/wasm-code-caching/"/><updated>2019-06-17T00:00:00+00:00</updated><id>https://v8.js.cn/blog/wasm-code-caching/</id><author><name>Bill Budge, putting the Ca-ching! in caching</name></author><content type="html">&lt;p&gt;There’s a saying among developers that the fastest code is code that doesn’t run. Likewise, the fastest compiling code is code that doesn’t have to be compiled. WebAssembly code caching is a new optimization in Chrome and V8 that tries to avoid code compilation by caching the native code produced by the compiler. We’ve &lt;a href=&quot;https://v8.js.cn/blog/code-caching&quot;&gt;written&lt;/a&gt; &lt;a href=&quot;https://v8.js.cn/blog/improved-code-caching&quot;&gt;about&lt;/a&gt; &lt;a href=&quot;https://v8.js.cn/blog/code-caching-for-devs&quot;&gt;how&lt;/a&gt; Chrome and V8 cache JavaScript code in the past, and best practices for taking advantage of this optimization. In this blog post, we describe the operation of Chrome’s WebAssembly code cache and how developers can take advantage of it to speed up loading for applications with large WebAssembly modules.&lt;/p&gt;
&lt;h2 id=&quot;recap&quot;&gt;WebAssembly compilation recap &lt;a class=&quot;bookmark&quot; href=&quot;#recap&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;WebAssembly is a way to run non-JavaScript code on the Web. A web app can use WebAssembly by loading a &lt;code&gt;.wasm&lt;/code&gt; resource, which contains partially compiled code from another language, such as C, C++, or Rust (and more to come.) The WebAssembly compiler’s job is to decode the &lt;code&gt;.wasm&lt;/code&gt; resource, validate that it is well-formed, and then compile it to native machine code that can be executed on the user’s machine.&lt;/p&gt;
&lt;p&gt;V8 has two compilers for WebAssembly: Liftoff and TurboFan. &lt;a href=&quot;https://v8.js.cn/blog/liftoff&quot;&gt;Liftoff&lt;/a&gt; is the baseline compiler, which compiles modules as quickly as possible so execution can begin as soon as possible. TurboFan is V8’s optimizing compiler for both JavaScript and WebAssembly. It runs in the background to generate high-quality native code to give a web app optimal performance over the long term. For large WebAssembly modules, TurboFan can take significant amounts of time — 30 seconds to a minute or more — to completely finish compiling a WebAssembly module to native code.&lt;/p&gt;
&lt;p&gt;That’s where code caching comes in. Once TurboFan has finished compiling a large WebAssembly module, Chrome can save the code in its cache so that the next time the module is loaded, we can skip both Liftoff and TurboFan compilation, leading to faster startup and reduced power consumption — compiling code is very CPU-intensive.&lt;/p&gt;
&lt;p&gt;WebAssembly code caching uses the same machinery in Chrome that is used for JavaScript code caching. We use the same type of storage, and the same double-keyed caching technique that keeps code compiled by different origins separate in accordance with &lt;a href=&quot;https://developers.google.com/web/updates/2018/07/site-isolation&quot;&gt;site isolation&lt;/a&gt;, an important Chrome security feature.&lt;/p&gt;
&lt;h2 id=&quot;algorithm&quot;&gt;WebAssembly code caching algorithm &lt;a class=&quot;bookmark&quot; href=&quot;#algorithm&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For now, WebAssembly caching is only implemented for the streaming API calls, &lt;code&gt;compileStreaming&lt;/code&gt; and &lt;code&gt;instantiateStreaming&lt;/code&gt;. These operate on an HTTP fetch of a &lt;code&gt;.wasm&lt;/code&gt; resource, making it easier to use Chrome’s resource fetching and caching mechanisms, and providing a handy resource URL to use as the key to identify the WebAssembly module. The caching algorithm works as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;When a &lt;code&gt;.wasm&lt;/code&gt; resource is first requested (i.e. a &lt;em&gt;cold run&lt;/em&gt;), Chrome downloads it from the network and streams it to V8 to compile. Chrome also stores the &lt;code&gt;.wasm&lt;/code&gt; resource in the browser’s resource cache, stored in the file system of the user’s device. This resource cache allows Chrome to load the resource faster the next time it’s needed.&lt;/li&gt;
&lt;li&gt;When TurboFan has completely finished compiling the module, and if the &lt;code&gt;.wasm&lt;/code&gt; resource is large enough (currently 128 kB), Chrome writes the compiled code to the WebAssembly code cache. This code cache is physically separate from the resource cache in step 1.&lt;/li&gt;
&lt;li&gt;When a &lt;code&gt;.wasm&lt;/code&gt; resource is requested a second time (i.e. a &lt;em&gt;hot run&lt;/em&gt;), Chrome loads the &lt;code&gt;.wasm&lt;/code&gt; resource from the resource cache and simultaneously queries the code cache. If there is a cache hit, then the compiled module bytes are sent to the renderer process and passed to V8 which deserializes the code instead of compiling the module. Deserializing is faster and less CPU-intensive than compiling.&lt;/li&gt;
&lt;li&gt;It may be that the cached code is no longer valid. This can happen because the &lt;code&gt;.wasm&lt;/code&gt; resource has changed, or because V8 has changed, something that is expected to happen at least every 6 weeks because of Chrome’s rapid release cycle. In this case the cached native code is cleared from the cache, and compilation proceeds as in step 1.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on this description, we can give some recommendations for improving your website’s use of the WebAssembly code cache.&lt;/p&gt;
&lt;h2 id=&quot;stream&quot;&gt;Tip 1: use the WebAssembly streaming API &lt;a class=&quot;bookmark&quot; href=&quot;#stream&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since code caching only works with the streaming API, compile or instantiate your WebAssembly module with &lt;code&gt;compileStreaming&lt;/code&gt; or &lt;code&gt;instantiateStreaming&lt;/code&gt;, as in this JavaScript snippet:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; fetchPromise &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&#39;fibonacci.wasm&#39;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; instance &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;await&lt;/span&gt; WebAssembly&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;instantiateStreaming&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;fetchPromise&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; result &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; instance&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;exports&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;fibonacci&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  console&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;result&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;a href=&quot;https://developers.google.com/web/updates/2018/04/loading-wasm&quot;&gt;article&lt;/a&gt; goes into detail about the advantages of using the WebAssembly streaming API. Emscripten tries to use this API by default when it generates loader code for your app. Note that streaming requires that the &lt;code&gt;.wasm&lt;/code&gt; resource has the correct MIME type, so the server must send the &lt;code&gt;Content-Type: application/wasm&lt;/code&gt; header in its response.&lt;/p&gt;
&lt;h2 id=&quot;cache-friendly&quot;&gt;Tip 2: be cache-friendly &lt;a class=&quot;bookmark&quot; href=&quot;#cache-friendly&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since code caching depends on the resource URL and whether the &lt;code&gt;.wasm&lt;/code&gt; resource is up-to-date, developers should try to keep those both stable. If the &lt;code&gt;.wasm&lt;/code&gt; resource is fetched from a different URL, it is considered different and V8 has to compile the module again. Similarly, if the &lt;code&gt;.wasm&lt;/code&gt; resource is no longer valid in the resource cache, then Chrome has to throw away any cached code.&lt;/p&gt;
&lt;h3 id=&quot;keep-code-stable&quot;&gt;Keep your code stable &lt;a class=&quot;bookmark&quot; href=&quot;#keep-code-stable&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Whenever you ship a new WebAssembly module, it must be completely recompiled. Ship new versions of your code only when necessary to deliver new features or fix bugs. When your code hasn’t changed, let Chrome know. When the browser makes an HTTP request for a resource URL, such as a WebAssembly module, it includes the date and time of the last fetch of that URL. If the server knows that the file hasn’t changed, it can send back a &lt;code&gt;304 Not Modified&lt;/code&gt; response, which tells Chrome and V8 that the cached resource and therefore the cached code are still valid. On the other hand, returning a &lt;code&gt;200 OK&lt;/code&gt; response updates the cached &lt;code&gt;.wasm&lt;/code&gt; resource and invalidates the code cache, reverting WebAssembly back to a cold run. Follow &lt;a href=&quot;https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching&quot;&gt;web resource best practices&lt;/a&gt; by using the response to inform the browser about whether the &lt;code&gt;.wasm&lt;/code&gt; resource is cacheable, how long it’s expected to be valid, or when it was last modified.&lt;/p&gt;
&lt;h3 id=&quot;url&quot;&gt;Don’t change your code’s URL &lt;a class=&quot;bookmark&quot; href=&quot;#url&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Cached compiled code is associated with the URL of the &lt;code&gt;.wasm&lt;/code&gt; resource, which makes it easy to look up without having to scan the actual resource. This means that changing the URL of a resource (including any query parameters!) creates a new entry in our resource cache, which also requires a complete recompile and creates a new code cache entry.&lt;/p&gt;
&lt;h3 id=&quot;go-big&quot;&gt;Go big (but not too big!) &lt;a class=&quot;bookmark&quot; href=&quot;#go-big&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The principal heuristic of WebAssembly code caching is the size of the &lt;code&gt;.wasm&lt;/code&gt; resource. If the &lt;code&gt;.wasm&lt;/code&gt; resource is smaller than a certain threshold size, we don’t cache the compiled module bytes. The reasoning here is that V8 can compile small modules quickly, possibly faster than loading the compiled code from the cache. At the moment, the cutoff is for &lt;code&gt;.wasm&lt;/code&gt; resources of 128 kB or more.&lt;/p&gt;
&lt;p&gt;But bigger is better only up to a point. Because caches take up space on the user’s machine, Chrome is careful not to consume too much space. Right now, on desktop machines, the code caches typically hold a few hundred megabytes of data. Since the Chrome caches also restrict the largest entries in the cache to some fraction of the total cache size, there is a further limit of about 150 MB for the compiled WebAssembly code (half the total cache size). It is important to note that compiled modules are often 5–7 times larger than the corresponding &lt;code&gt;.wasm&lt;/code&gt; resource on a typical desktop machine.&lt;/p&gt;
&lt;p&gt;This size heuristic, like the rest of the caching behavior, may change as we determine what works best for users and developers.&lt;/p&gt;
&lt;h3 id=&quot;service-worker&quot;&gt;Use a service worker &lt;a class=&quot;bookmark&quot; href=&quot;#service-worker&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;WebAssembly code caching is enabled for workers and service workers, so it’s possible to use them to load, compile, and cache a new version of code so it’s available the next time your app starts. Every web site must perform at least one full compilation of a WebAssembly module — use workers to hide that from your users.&lt;/p&gt;
&lt;h2 id=&quot;tracing&quot;&gt;Tracing &lt;a class=&quot;bookmark&quot; href=&quot;#tracing&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As a developer, you might want to check that your compiled module is being cached by Chrome. WebAssembly code caching events are not exposed by default in Chrome’s Developer Tools, so the best way to find out whether your modules are being cached is to use the slightly lower-level &lt;code&gt;chrome://tracing&lt;/code&gt; feature.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;chrome://tracing&lt;/code&gt; records instrumented traces of Chrome during some period of time. Tracing records the behavior of the entire browser, including other tabs, windows, and extensions, so it works best when done in a clean user profile, with extensions disabled, and with no other browser tabs open:&lt;/p&gt;
&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Start a new Chrome browser session with a clean user profile and extensions disabled&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;google-chrome --user-data-dir&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;&lt;span class=&quot;token variable&quot;&gt;&lt;span class=&quot;token variable&quot;&gt;$(&lt;/span&gt;mktemp -d&lt;span class=&quot;token variable&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&quot;&lt;/span&gt; --disable-extensions&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Navigate to &lt;code&gt;chrome://tracing&lt;/code&gt; and click ‘Record’ to begin a tracing session. On the dialog window that appears, click ‘Edit Categories’ and check the &lt;code&gt;devtools.timeline&lt;/code&gt; category on the right side under ‘Disabled by Default Categories’ (you can uncheck any other pre-selected categories to reduce the amount of data collected). Then click the ‘Record’ button on the dialog to begin the trace.&lt;/p&gt;
&lt;p&gt;In another tab load or reload your app. Let it run long enough, 10 seconds or more, to make sure TurboFan compilation completes. When done, click ‘Stop’ to end the trace. A timeline view of events appears. At the top right of the tracing window, there is a text box, just to the right of ‘View Options’. Type &lt;code&gt;v8.wasm&lt;/code&gt; to filter out non-WebAssembly events. You should see one or more of the following events:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;v8.wasm.streamFromResponseCallback&lt;/code&gt; — The resource fetch passed to instantiateStreaming received a response.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v8.wasm.compiledModule&lt;/code&gt; — TurboFan finished compiling the &lt;code&gt;.wasm&lt;/code&gt; resource.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v8.wasm.cachedModule&lt;/code&gt; — Chrome wrote the compiled module to the code cache.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v8.wasm.moduleCacheHit&lt;/code&gt; — Chrome found the code in its cache while loading the &lt;code&gt;.wasm&lt;/code&gt; resource.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v8.wasm.moduleCacheInvalid&lt;/code&gt; — V8 wasn’t able to deserialize the cached code because it was out of date.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On a cold run, we expect to see &lt;code&gt;v8.wasm.streamFromResponseCallback&lt;/code&gt; and &lt;code&gt;v8.wasm.compiledModule&lt;/code&gt; events. This indicates that the WebAssembly module was received, and compilation succeeded. If neither event is observed, check that your WebAssembly streaming API calls are working correctly.&lt;/p&gt;
&lt;p&gt;After a cold run, if the size threshold was exceeded, we also expect to see a &lt;code&gt;v8.wasm.cachedModule&lt;/code&gt; event, meaning that the compiled code was sent to the cache. It is possible that we get this event but that the write doesn’t succeed for some reason. There is currently no way to observe this, but metadata on the events can show the size of the code. Very large modules may not fit in the cache.&lt;/p&gt;
&lt;p&gt;When caching is working correctly, a hot run produces two events: &lt;code&gt;v8.wasm.streamFromResponseCallback&lt;/code&gt; and &lt;code&gt;v8.wasm.moduleCacheHit&lt;/code&gt;. The metadata on these events allows you to see the size of the compiled code.&lt;/p&gt;
&lt;p&gt;For more on using &lt;code&gt;chrome://tracing&lt;/code&gt;, see &lt;a href=&quot;https://v8.js.cn/blog/code-caching-for-devs&quot;&gt;our article on JavaScript (byte)code caching for developers&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a class=&quot;bookmark&quot; href=&quot;#conclusion&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For most developers, code caching should “just work”. It works best, like any cache, when things are stable. Chrome’s caching heuristics may change between versions, but code caching does have behaviors that can be used, and limitations which can be avoided. Careful analysis using &lt;code&gt;chrome://tracing&lt;/code&gt; can help you tweak and optimize the use of the WebAssembly code cache by your web app.&lt;/p&gt;
</content></entry><entry><title>V8 release v7.5</title><link href="https://v8.js.cn/blog/v8-release-75/"/><updated>2019-05-16T15:00:00+00:00</updated><id>https://v8.js.cn/blog/v8-release-75/</id><author><name>Dan Elphick, scourge of the deprecated</name></author><content type="html">&lt;p&gt;Every six weeks, we create a new branch of V8 as part of our &lt;a href=&quot;https://v8.js.cn/docs/release-process&quot;&gt;release process&lt;/a&gt;. Each version is branched from V8’s Git master immediately before a Chrome Beta milestone. Today we’re pleased to announce our newest branch, &lt;a href=&quot;https://chromium.googlesource.com/v8/v8.git/+log/branch-heads/7.5&quot;&gt;V8 version 7.5&lt;/a&gt;, which is in beta until its release in coordination with Chrome 75 Stable in several weeks. V8 v7.5 is filled with all sorts of developer-facing goodies. This post provides a preview of some of the highlights in anticipation of the release.&lt;/p&gt;
&lt;h2 id=&quot;webassembly&quot;&gt;WebAssembly &lt;a class=&quot;bookmark&quot; href=&quot;#webassembly&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;implicit-caching&quot;&gt;Implicit caching &lt;a class=&quot;bookmark&quot; href=&quot;#implicit-caching&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We are planning to roll out implicit caching of WebAssembly compilation artifacts in Chrome 75. This means users that visit the same page a second time don’t need to compile the already-seen WebAssembly modules. Instead they are loaded from the cache. This works similarly to &lt;a href=&quot;https://v8.js.cn/blog/code-caching-for-devs&quot;&gt;Chromium’s JavaScript code-cache&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In case you want to use a similar feature in your V8 embedding, please take inspiration from Chromium’s implementation.&lt;/p&gt;
&lt;h3 id=&quot;bulk-memory-operations&quot;&gt;Bulk memory operations &lt;a class=&quot;bookmark&quot; href=&quot;#bulk-memory-operations&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/webassembly/bulk-memory-operations&quot;&gt;The bulk memory proposal&lt;/a&gt; adds new instructions to WebAssembly for updating large regions of memory or tables.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;memory.copy&lt;/code&gt; copies data from one region to another, even if the regions are overlapping (like C’s &lt;code&gt;memmove&lt;/code&gt;). &lt;code&gt;memory.fill&lt;/code&gt; fills a region with a given byte (like C’s &lt;code&gt;memset&lt;/code&gt;). Similar to &lt;code&gt;memory.copy&lt;/code&gt;, &lt;code&gt;table.copy&lt;/code&gt; copies from one region of a table to another, even if the regions are overlapping.&lt;/p&gt;
&lt;pre class=&quot;language-wasm&quot;&gt;&lt;code class=&quot;language-wasm&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;;; Copy 500 bytes from source 1000 to destination 0.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;memory&lt;/span&gt;.copy &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;;; Fill 1000 bytes starting at 100 with the value `123`.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;memory&lt;/span&gt;.fill &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;123&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;;; Copy 10 table elements from source 5 to destination 15.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;table&lt;/span&gt;.copy &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The proposal also provides a way to copy a constant region into linear memory or a table. To do so, we first need to define a “passive” segment. Unlike “active” segments, these segments are not initialized during module instantiation. Instead they can be copied into a memory or table region using the &lt;code&gt;memory.init&lt;/code&gt; and &lt;code&gt;table.init&lt;/code&gt; instructions.&lt;/p&gt;
&lt;pre class=&quot;language-wasm&quot;&gt;&lt;code class=&quot;language-wasm&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;;; Define a passive data segment.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;token variable&quot;&gt;$hello&lt;/span&gt; passive &lt;span class=&quot;token string&quot;&gt;&quot;Hello WebAssembly&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;;; Copy &quot;Hello&quot; into memory at address 10.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;memory&lt;/span&gt;.init &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;;; Copy &quot;WebAssembly&quot; into memory at address 1000.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;memory&lt;/span&gt;.init &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;i32&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;const&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;numeric-separators&quot;&gt;Numeric separators in JavaScript &lt;a class=&quot;bookmark&quot; href=&quot;#numeric-separators&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Large numeric literals are difficult for the human eye to parse quickly, especially when there are lots of repeating digits:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token number&quot;&gt;1000000000000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;   &lt;span class=&quot;token number&quot;&gt;1019436871.42&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To improve readability, &lt;a href=&quot;https://v8.js.cn/features/numeric-separators&quot;&gt;a new JavaScript language feature&lt;/a&gt; enables underscores as separators in numeric literals. So, the above can now be rewritten to group the digits per thousand, for example:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token number&quot;&gt;1_000_000_000_000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token number&quot;&gt;1_019_436_871.42&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now it’s easier to tell that the first number is a trillion, and the second number is in the order of 1 billion.&lt;/p&gt;
&lt;p&gt;For more examples and additional information about numeric separators, see &lt;a href=&quot;https://v8.js.cn/features/numeric-separators&quot;&gt;our explainer&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;performance&quot;&gt;Performance &lt;a class=&quot;bookmark&quot; href=&quot;#performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;script-streaming-directly-from-network&quot;&gt;Script streaming directly from network &lt;a class=&quot;bookmark&quot; href=&quot;#script-streaming-directly-from-network&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As of Chrome 75, V8 can stream scripts directly from network into the streaming parser, without waiting for the Chrome main thread.&lt;/p&gt;
&lt;p&gt;While previous Chrome versions had streaming parsing and compilation, the script source data coming in from the network always had to make its way to the Chrome main thread first before being forwarded to the streamer, for historical reasons. This meant that often, the streaming parser would be waiting for data that has arrived from the network already, but hadn’t been forwarded to the streaming task yet because it was blocked by other things happening on the main thread (such as HTML parsing, layout, or other JavaScript execution).&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-75/before.jpg&quot; srcset=&quot;https://v8.js.cn/_img/v8-release-75/before@2x.jpg 2x&quot; intrinsicsize=&quot;1133x638&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Stalled background parsing tasks in Chrome 74 and older&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;In Chrome 75, we connect the network “data pipe” directly to V8, allowing us to read network data directly during streaming parsing, skipping the dependency on the main thread.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/v8-release-75/after.jpg&quot; srcset=&quot;https://v8.js.cn/_img/v8-release-75/after@2x.jpg 2x&quot; intrinsicsize=&quot;1133x638&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;In Chrome 75+, background parsing tasks are no longer blocked by activity on the main thread.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;This allows us to finish streaming compiles earlier, improving the loading time of pages using streaming compilation, as well as reducing the number of concurrent (but stalled) streaming parse tasks, which reduces memory consumption.&lt;/p&gt;
&lt;h2 id=&quot;v8-api&quot;&gt;V8 API &lt;a class=&quot;bookmark&quot; href=&quot;#v8-api&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Please use &lt;code&gt;git log branch-heads/7.4..branch-heads/7.5 include/v8.h&lt;/code&gt; to get a list of the API changes.&lt;/p&gt;
&lt;p&gt;Developers with an &lt;a href=&quot;https://v8.js.cn/docs/source-code#using-git&quot;&gt;active V8 checkout&lt;/a&gt; can use &lt;code&gt;git checkout -b 7.5 -t branch-heads/7.5&lt;/code&gt; to experiment with the new features in V8 v7.5. Alternatively you can &lt;a href=&quot;https://www.google.com/chrome/browser/beta.html&quot;&gt;subscribe to Chrome’s Beta channel&lt;/a&gt; and try the new features out yourself soon.&lt;/p&gt;
</content></entry><entry><title>Faster and more feature-rich internationalization APIs</title><link href="https://v8.js.cn/blog/intl/"/><updated>2019-04-25T16:45:37+00:00</updated><id>https://v8.js.cn/blog/intl/</id><author><name>சத்யா குணசேகரன் (Sathya Gunasekaran)</name></author><content type="html">&lt;p&gt;&lt;a href=&quot;https://tc39.es/ecma402/&quot;&gt;The ECMAScript Internationalization API Specification&lt;/a&gt; (ECMA-402, or &lt;code&gt;Intl&lt;/code&gt;) provides key locale-specific functionality such as date formatting, number formatting, plural form selection, and collation. The Chrome V8 and Google Internationalization teams have been collaborating on adding features to V8’s ECMA-402 implementation, while cleaning up technical debt and improving performance and interoperability with other browsers.&lt;/p&gt;
&lt;h2 id=&quot;underlying-architectural-improvements&quot;&gt;Underlying architectural improvements &lt;a class=&quot;bookmark&quot; href=&quot;#underlying-architectural-improvements&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Initially the ECMA-402 spec was implemented mostly in JavaScript using V8-extensions and lived outside the V8 codebase. Using the external Extension API meant that several of V8’s internally used APIs for type checking, lifetime management of external C++ objects and internal private data storage couldn’t be used. As part of improving startup performance, this implementation was later moved in to the V8 codebase to enable &lt;a href=&quot;https://v8.js.cn/blog/custom-startup-snapshots&quot;&gt;snapshotting&lt;/a&gt; of these builtins.&lt;/p&gt;
&lt;p&gt;V8 uses specialized &lt;code&gt;JSObject&lt;/code&gt;s with custom &lt;a href=&quot;https://mathiasbynens.be/notes/shapes-ics&quot;&gt;shapes (hidden classes)&lt;/a&gt; to describe built-in JavaScript objects specified by ECMAScript (like &lt;code&gt;Promise&lt;/code&gt;s, &lt;code&gt;Map&lt;/code&gt;s, &lt;code&gt;Set&lt;/code&gt;s, etc). With this approach, V8 can pre-allocate the required number of internal slots and generate fast accesses to these, rather than grow the object one property at a time leading to slower performance and worse memory usage.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Intl&lt;/code&gt; implementation was not modeled after such an architecture, as a consequence of the historic split. Instead, all the built-in JavaScript objects as specified by the Internationalization spec (like &lt;code&gt;NumberFormat&lt;/code&gt;, &lt;code&gt;DateTimeFormat&lt;/code&gt;) were generic &lt;code&gt;JSObject&lt;/code&gt;s that had to transition through several property additions for their internal slots.&lt;/p&gt;
&lt;p&gt;Another artifact of not having a specialized &lt;code&gt;JSObject&lt;/code&gt;s was that type checking was now more complex. The type information was stored under a private symbol and type-checked on both the JS and C++ side using expensive property access, rather than just looking up its shape.&lt;/p&gt;
&lt;h3 id=&quot;modernizing-the-codebase&quot;&gt;Modernizing the codebase &lt;a class=&quot;bookmark&quot; href=&quot;#modernizing-the-codebase&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the current move away from writing self-hosted builtins in V8, it made sense to use this opportunity to modernize the ECMA402 implementation.&lt;/p&gt;
&lt;h3 id=&quot;moving-away-from-self-hosted-js&quot;&gt;Moving away from self-hosted JS &lt;a class=&quot;bookmark&quot; href=&quot;#moving-away-from-self-hosted-js&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Although self-hosting lends itself to concise and readable code, the frequent usage of slow runtime calls to access ICU APIs led to performance issues. As a result, a lot of ICU functionality was duplicated in JavaScript to reduce the number of such runtime calls.&lt;/p&gt;
&lt;p&gt;By rewriting the builtins in C++, it became much faster to access the ICU APIs as there is no runtime call overhead now.&lt;/p&gt;
&lt;h3 id=&quot;improving-icu&quot;&gt;Improving ICU &lt;a class=&quot;bookmark&quot; href=&quot;#improving-icu&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;ICU is a set of C/C++ libraries used by a large set of applications, including all the major JavaScript engines, for providing Unicode and globalization support. As part of switching &lt;code&gt;Intl&lt;/code&gt; to ICU in V8’s implementation, we &lt;a href=&quot;https://unicode-org.atlassian.net/browse/ICU-20140&quot;&gt;found&lt;/a&gt; &lt;a href=&quot;https://unicode-org.atlassian.net/browse/ICU-9562&quot;&gt;and&lt;/a&gt; &lt;a href=&quot;https://unicode-org.atlassian.net/browse/ICU-20098&quot;&gt;fixed&lt;/a&gt; several ICU bugs.&lt;/p&gt;
&lt;p&gt;As part of implementing new proposals such as &lt;a href=&quot;https://v8.js.cn/features/intl-relativetimeformat&quot;&gt;&lt;code&gt;Intl.RelativeTimeFormat&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://v8.js.cn/features/intl-listformat&quot;&gt;&lt;code&gt;Intl.ListFormat&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;Intl.Locale&lt;/code&gt;, we’ve extended ICU by adding &lt;a href=&quot;https://unicode-org.atlassian.net/browse/ICU-13256&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://unicode-org.atlassian.net/browse/ICU-20121&quot;&gt;new&lt;/a&gt; &lt;a href=&quot;https://unicode-org.atlassian.net/browse/ICU-20342&quot;&gt;APIs&lt;/a&gt; to support these new ECMAScript proposals.&lt;/p&gt;
&lt;p&gt;All of these additions help other JavaScript engines implement these proposals quicker now, pushing the web forward! For example, development is in progress in Firefox on implementing several new &lt;code&gt;Intl&lt;/code&gt; APIs based on our ICU work.&lt;/p&gt;
&lt;h2 id=&quot;performance&quot;&gt;Performance &lt;a class=&quot;bookmark&quot; href=&quot;#performance&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As a result of this work, we improved the performance of the Internationalization API by optimizing several fast paths and caching the initialization of the various &lt;code&gt;Intl&lt;/code&gt; objects and the &lt;code&gt;toLocaleString&lt;/code&gt; methods on &lt;code&gt;Number.prototype&lt;/code&gt;, &lt;code&gt;Date.prototype&lt;/code&gt;, and &lt;code&gt;String.prototype&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, creating a new &lt;code&gt;Intl.NumberFormat&lt;/code&gt; object became around 24× faster.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/intl/performance.svg&quot; intrinsicsize=&quot;713x371&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;&lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/test/js-perf-test/Intl/constructor.js&quot;&gt;Microbenchmarks&lt;/a&gt; testing the performance of creating various &lt;code&gt;Intl&lt;/code&gt; objects&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Note that for better performance, it’s recommended to explicitly create &lt;em&gt;and reuse&lt;/em&gt; an &lt;code&gt;Intl.NumberFormat&lt;/code&gt; or &lt;code&gt;Intl.DateTimeFormat&lt;/code&gt; or &lt;code&gt;Intl.Collator&lt;/code&gt; object, rather than calling methods like &lt;code&gt;toLocaleString&lt;/code&gt; or &lt;code&gt;localeCompare&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;new-intl-features&quot;&gt;New &lt;code&gt;Intl&lt;/code&gt; features &lt;a class=&quot;bookmark&quot; href=&quot;#new-intl-features&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All of this work has provided a great foundation to build new features on and we’re continuing to ship all the new Internationalization proposals that are in Stage 3.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://v8.js.cn/features/intl-relativetimeformat&quot;&gt;&lt;code&gt;Intl.RelativeTimeFormat&lt;/code&gt;&lt;/a&gt; has shipped in Chrome 71, &lt;a href=&quot;https://v8.js.cn/features/intl-listformat&quot;&gt;&lt;code&gt;Intl.ListFormat&lt;/code&gt;&lt;/a&gt; has shipped in Chrome 72, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Locale&quot;&gt;&lt;code&gt;Intl.Locale&lt;/code&gt;&lt;/a&gt; has shipped in Chrome 74, and &lt;a href=&quot;https://github.com/tc39/proposal-intl-datetime-style&quot;&gt;&lt;code&gt;dateStyle&lt;/code&gt; and &lt;code&gt;timeStyle&lt;/code&gt; options for &lt;code&gt;Intl.DateTimeFormat&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/tc39/ecma402/pull/236&quot;&gt;BigInt support for &lt;code&gt;Intl.DateTimeFormat&lt;/code&gt;&lt;/a&gt; are shipping in Chrome 76. &lt;a href=&quot;https://github.com/tc39/proposal-intl-DateTimeFormat-formatRange&quot;&gt;&lt;code&gt;Intl.DateTimeFormat#formatRange&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://github.com/tc39/proposal-intl-segmenter/&quot;&gt;&lt;code&gt;Intl.Segmenter&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;https://github.com/tc39/proposal-unified-intl-numberformat/&quot;&gt;additional options for &lt;code&gt;Intl.NumberFormat&lt;/code&gt;&lt;/a&gt; are currently under development in V8, and we hope to ship them soon!&lt;/p&gt;
&lt;p&gt;Many of these new APIs, and others further down the pipeline, are due to our work on standardizing new features to help developers with internationalization. &lt;a href=&quot;https://github.com/tc39/proposal-intl-displaynames&quot;&gt;&lt;code&gt;Intl.DisplayNames&lt;/code&gt;&lt;/a&gt; is a Stage 1 proposal that allows users to localize the display names of language, region or script display names. &lt;a href=&quot;https://github.com/fabalbon/proposal-intl-DateTimeFormat-formatRange&quot;&gt;&lt;code&gt;Intl.DateTimeFormat#formatRange&lt;/code&gt;&lt;/a&gt; is a Stage 3 proposal that specifies a way to format date ranges in a concise and locale-aware manner. &lt;a href=&quot;https://github.com/tc39/proposal-unified-intl-numberformat&quot;&gt;The unified &lt;code&gt;Intl.NumberFormat&lt;/code&gt; API proposal&lt;/a&gt; is a Stage 3 proposal that improves &lt;code&gt;Intl.NumberFormat&lt;/code&gt; by adding support for measurement units, currency and sign display policies, and scientific and compact notation. You can get involved in the future of ECMA-402 as well, by contributing at &lt;a href=&quot;https://github.com/tc39/ecma402&quot;&gt;its GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a class=&quot;bookmark&quot; href=&quot;#conclusion&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Intl&lt;/code&gt; provides a feature-rich API for several operations needed in internationalizing your web app, leaving the heavy lifting to the browser, without shipping as much data or code over the wire. Thinking through the proper use of these APIs can lead your UI to work better in different locales. Due to the work by the Google V8 and i18n teams in collaboration with TC39 and its ECMA-402 subgroup, you can now access more functionality with better performance, and expect further improvements over time.&lt;/p&gt;
</content></entry><entry><title>A year with Spectre: a V8 perspective</title><link href="https://v8.js.cn/blog/spectre/"/><updated>2019-04-23T14:15:22+00:00</updated><id>https://v8.js.cn/blog/spectre/</id><author><name>Ben L. Titzer and Jaroslav Sevcik</name></author><content type="html">&lt;p&gt;On January 3, 2018, Google Project Zero and others &lt;a href=&quot;https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html&quot;&gt;disclosed&lt;/a&gt; the first three of a new class of vulnerabilities that affect CPUs that perform speculative execution, dubbed &lt;a href=&quot;https://spectreattack.com/spectre.pdf&quot;&gt;Spectre&lt;/a&gt; and &lt;a href=&quot;https://meltdownattack.com/meltdown.pdf&quot;&gt;Meltdown&lt;/a&gt;. Using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Speculative_execution&quot;&gt;speculative execution&lt;/a&gt; mechanisms of CPUs, an attacker could temporarily bypass both implicit and explicit safety checks in code that prevent programs from reading unauthorized data in memory. While processor speculation was designed to be a microarchitectural detail, invisible at the architectural level, carefully crafted programs could read unauthorized information in speculation and disclose it through side channels such as the execution time of a program fragment.&lt;/p&gt;
&lt;p&gt;When it was shown that JavaScript could be used to mount Spectre attacks, the V8 team became involved in tackling the problem. We formed an emergency response team and worked closely with other teams at Google, our partners at other browser vendors, and our hardware partners. In concert with them, we proactively engaged in both offensive research (constructing proof-of-concept gadgets) and defensive research (mitigations for potential attacks).&lt;/p&gt;
&lt;p&gt;A Spectre attack consists of two parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Leak of otherwise-inaccessible data into hidden CPU state.&lt;/em&gt; All known Spectre attacks use speculation to leak bits of inaccessible data into CPU caches.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Extract the hidden state&lt;/em&gt; to recover the inaccessible data. For this, the attacker needs a clock of sufficient precision. (Surprisingly low-resolution clocks can be sufficient, especially with techniques such as edge thresholding.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In theory, it would be sufficient to defeat either of the two components of an attack. Since we do not know of any way to defeat any of the parts perfectly, we designed and deployed mitigations that greatly reduce the amount of information that is leaked into CPU caches &lt;em&gt;and&lt;/em&gt; mitigations that make it hard to recover the hidden state.&lt;/p&gt;
&lt;h2 id=&quot;high-precision-timers&quot;&gt;High-precision timers &lt;a class=&quot;bookmark&quot; href=&quot;#high-precision-timers&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The tiny state changes that can survive speculative execution give rise to correspondingly tiny, almost impossibly tiny, timing differences — on the order of a billionth of a second. To directly detect individual such differences, an attacker program needs a high precision timer. CPUs offer such timers, but the Web Platform does not expose them. The Web Platform’s most precise timer, &lt;code&gt;performance.now()&lt;/code&gt;, had a resolution of single-digit micro-seconds, which was originally thought unusable for this purpose. Yet two years ago, an academic research team specializing in micro-architectural attacks published &lt;a href=&quot;https://gruss.cc/files/fantastictimers.pdf&quot;&gt;a paper&lt;/a&gt; that studied the availability of timers in the web platform. They concluded that concurrent mutable shared memory and various resolution-recovery techniques could allow the construction of even higher resolution timers, down to nanosecond resolution. Such timers are precise enough to detect individual L1 cache hits and misses, which is usually how Spectre gadgets leak information.&lt;/p&gt;
&lt;h2 id=&quot;timer-mitigations&quot;&gt;Timer mitigations &lt;a class=&quot;bookmark&quot; href=&quot;#timer-mitigations&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To disrupt the ability to detect small timing differences, browser vendors took a multi-pronged approach. On all browsers, the resolution of &lt;code&gt;performance.now()&lt;/code&gt; was reduced (in Chrome, from 5 microseconds to 100), and random uniform jitter was introduced to prevent resolution recovery. After consultation among all the vendors, together we decided to take the unprecedented step of immediately and retroactively disabling the &lt;code&gt;SharedArrayBuffer&lt;/code&gt; API across all browsers in order to prevent the construction of a nanosecond timer that could be used for Spectre attacks.&lt;/p&gt;
&lt;h2 id=&quot;amplification&quot;&gt;Amplification &lt;a class=&quot;bookmark&quot; href=&quot;#amplification&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It became clear early on in our offensive research that timer mitigations alone would not be sufficient. One reason why is that an attacker may simply repeatedly execute their gadget so that the cumulative time difference is much larger than a single cache hit or miss. We were able to engineer reliable gadgets that use many cache lines at a time, up to the cache capacity, yielding timing differences as large as 600 microseconds. We later discovered arbitrary amplification techniques that are not limited by the cache capacity. Such amplification techniques rely on multiple attempts to read the secret data.&lt;/p&gt;
&lt;h2 id=&quot;jit-mitigations&quot;&gt;JIT mitigations &lt;a class=&quot;bookmark&quot; href=&quot;#jit-mitigations&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To read inaccessible data using Spectre, the attacker tricks the CPU into speculatively executing code that reads normally inaccessible data and encodes it into the cache. The attack can be broken in two ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Prevent speculative execution of code.&lt;/li&gt;
&lt;li&gt;Prevent speculative execution from reading inaccessible data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We have experimented with (1) by inserting the recommended speculation barrier instructions, such as Intel’s &lt;code&gt;LFENCE&lt;/code&gt;, on every critical conditional branch, and by using &lt;a href=&quot;https://support.google.com/faqs/answer/7625886&quot;&gt;retpolines&lt;/a&gt; for indirect branches. Unfortunately, such heavy-handed mitigations greatly reduce performance (2–3× slowdown on the Octane benchmark). Instead, we chose approach (2), inserting mitigation sequences that prevent reading secret data due to mis-speculation. Let us illustrate the technique on the following code snippet:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;condition&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; a&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For simplicity, let us assume condition is &lt;code&gt;0&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt;. The code above is vulnerable if the CPU speculatively reads from &lt;code&gt;a[i]&lt;/code&gt; when &lt;code&gt;i&lt;/code&gt; is out-of-bounds, accessing normally inaccessible data. The important observation is that in such case, the speculation tries to read &lt;code&gt;a[i]&lt;/code&gt; when &lt;code&gt;condition&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;. Our mitigation rewrites this program so that it behaves exactly like the original program but does not leak any speculatively loaded data.&lt;/p&gt;
&lt;p&gt;We reserve one CPU register which we call the poison to track whether code is executing in a mispredicted branch. The poison register is maintained across all branches and calls in generated code, so that any mispredicted branch causes the poison register to become &lt;code&gt;0&lt;/code&gt;. Then we instrument all memory accesses so that they unconditionally mask the result of all loads with the current value of the poison register. This does not prevent the processor from predicting (or mispredicting) branches, but destroys the information of (potentially out-of-bounds) loaded values due to mispredicted branches. The instrumented code is shown below (assuming that &lt;code&gt;a&lt;/code&gt; is a number array).&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;mark class=&quot;highlight-line highlight-line-active&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; poison &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/mark&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// …&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;condition&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;mark class=&quot;highlight-line highlight-line-active&quot;&gt;  poison &lt;span class=&quot;token operator&quot;&gt;*=&lt;/span&gt; condition&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/mark&gt;&lt;br&gt;&lt;mark class=&quot;highlight-line highlight-line-active&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; a&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; poison&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/mark&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The additional code does not have any effect on the normal (architecturally-defined) behavior of the program. It only affects micro-architectural state when running on speculating CPUs. If the program was instrumented at source level, advanced optimizations in modern compilers might remove such instrumentation. In V8, we prevent our compiler from removing the mitigations by inserting them in a very late phase of compilation.&lt;/p&gt;
&lt;p&gt;We also use the poisoning technique to prevent leaks from misspeculated indirect branches in the interpreter’s bytecode dispatch loop and in the JavaScript function call sequence. In the interpreter, we set the poison to &lt;code&gt;0&lt;/code&gt; if the bytecode handler (i.e. the machine code sequence that interprets a single bytecode) does not match the current bytecode. For JavaScript calls, we pass the target function as a parameter (in a register) and we set the poison to &lt;code&gt;0&lt;/code&gt; at the beginning of each function if the incoming target function does not match the current function. With the poisoning mitigations in place, we see less than 20% slowdown on the Octane benchmark.&lt;/p&gt;
&lt;p&gt;The mitigations for WebAssembly are simpler, since the main safety check is to ensure memory accesses are within bounds. For 32-bit platforms, in addition to the normal bounds checks, we pad all memories to the next power of two and unconditionally mask off any upper bits of a user-supplied memory index. 64-bit platforms need no such mitigation, since the implementation uses virtual memory protection for bounds checks. We experimented with compiling switch/case statements to binary search code rather than using a potentially vulnerable indirect branch, but this is too expensive on some workloads. Indirect calls are protected with retpolines.&lt;/p&gt;
&lt;h2 id=&quot;software-mitigations-are-an-unsustainable-path&quot;&gt;Software mitigations are an unsustainable path &lt;a class=&quot;bookmark&quot; href=&quot;#software-mitigations-are-an-unsustainable-path&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Fortunately or unfortunately, our offensive research advanced much faster than our defensive research, and we quickly discovered that software mitigation of all possible leaks due to Spectre was infeasible. This was due to a variety of reasons. First, the engineering effort diverted to combating Spectre was disproportionate to its threat level. In V8 we face many other security threats that are much worse, from direct out-of-bound reads due to regular bugs (faster and more direct than Spectre), out-of-bound writes (impossible with Spectre, and worse) and potential remote code execution (impossible with Spectre and much, much worse). Second, the increasingly complicated mitigations that we designed and implemented carried significant complexity, which is technical debt and might actually increase the attack surface, and performance overheads. Third, testing and maintaining mitigations for microarchitectural leaks is even trickier than designing gadgets themselves, since it’s hard to be sure the mitigations continue working as designed. At least once, important mitigations were effectively undone by later compiler optimizations. Fourth, we found that effective mitigation of some variants of Spectre, particularly variant 4, to be simply infeasible in software, even after a heroic effort by our partners at Apple to combat the problem in their JIT compiler.&lt;/p&gt;
&lt;h2 id=&quot;site-isolation&quot;&gt;Site isolation &lt;a class=&quot;bookmark&quot; href=&quot;#site-isolation&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Our research reached the conclusion that, in principle, untrusted code can read a process’s entire address space using Spectre and side channels. Software mitigations reduce the effectiveness of many potential gadgets, but are not efficient or comprehensive. The only effective mitigation is to move sensitive data out of the process’s address space. Thankfully, Chrome already had an effort underway for many years to separate sites into different processes to reduce the attack surface due to conventional vulnerabilities. This investment paid off, and we productionized and deployed &lt;a href=&quot;https://developers.google.com/web/updates/2018/07/site-isolation&quot;&gt;site isolation&lt;/a&gt; for as many platforms as possible by May 2018. Thus Chrome’s security model no longer assumes language-enforced confidentiality within a renderer process.&lt;/p&gt;
&lt;p&gt;Spectre has been a long journey and has highlighted the best in collaboration across vendors in the industry and academia. So far, white hats appear to be ahead of black hats. We still know of no attacks in the wild, outside of the curious tinkerers and professional researchers developing proof of concept gadgets. New variants of these vulnerabilities continue to trickle out, and may continue to do so for some time. We continue to track these threats and take them seriously.&lt;/p&gt;
&lt;p&gt;Like many with a background in programming languages and their implementations, the idea that safe languages enforce a proper abstraction boundary, not allowing well-typed programs to read arbitrary memory, has been a guarantee upon which our mental models have been built. It is a depressing conclusion that our models were wrong — this guarantee is not true on today’s hardware. Of course, we still believe that safe languages have great engineering benefits and will continue to be the basis for the future, but… on today’s hardware they leak a little.&lt;/p&gt;
&lt;p&gt;Interested readers can dig into more details in &lt;a href=&quot;https://arxiv.org/pdf/1902.05178.pdf&quot;&gt;our whitepaper&lt;/a&gt;.&lt;/p&gt;
</content></entry><entry><title>Blazingly fast parsing, part 2: lazy parsing</title><link href="https://v8.js.cn/blog/preparser/"/><updated>2019-04-15T17:03:37+00:00</updated><id>https://v8.js.cn/blog/preparser/</id><author><name>Toon Verwaest (@tverwaes) and Marja Hölttä (@marjakh), sparser parsers</name></author><content type="html">&lt;p&gt;This is the second part of our series explaining how V8 parses JavaScript as fast as possible. The first part explained how we made V8’s &lt;a href=&quot;https://v8.js.cn/blog/scanner&quot;&gt;scanner&lt;/a&gt; fast.&lt;/p&gt;
&lt;p&gt;Parsing is the step where source code is turned into an intermediate representation to be consumed by a compiler (in V8, the bytecode compiler &lt;a href=&quot;https://v8.js.cn/blog/ignition-interpreter&quot;&gt;Ignition&lt;/a&gt;). Parsing and compiling happens on the critical path of web page startup, and not all functions shipped to the browser are immediately needed during startup. Even though developers can delay such code with async and deferred scripts, that’s not always feasible. Additionally, many web pages ship code that’s only used by certain features which may not be accessed by a user at all during any individual run of the page.&lt;/p&gt;
&lt;p&gt;Eagerly compiling code unnecessarily has real resource costs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU cycles are used to create the code, delaying the availability of code that’s actually needed for startup.&lt;/li&gt;
&lt;li&gt;Code objects take up memory, at least until &lt;a href=&quot;https://v8.js.cn/blog/v8-release-74#bytecode-flushing&quot;&gt;bytecode flushing&lt;/a&gt; decides that the code isn’t currently needed and allows it to be garbage-collected.&lt;/li&gt;
&lt;li&gt;Code compiled by the time the top-level script finishes executing ends up being cached on disk, taking up disk space.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For these reasons, all major browsers implement &lt;em&gt;lazy parsing&lt;/em&gt;. Instead of generating an abstract syntax tree (AST) for each function and then compiling it to bytecode, the parser can decide to “pre-parse” functions it encounters instead of fully parsing them. It does so by switching to &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/parsing/preparser.h?l=921&amp;amp;rcl=e3b2feb3aade83c02e4bd2fa46965a69215cd821&quot;&gt;the preparser&lt;/a&gt;, a copy of the parser that does the bare minimum needed to be able to otherwise skip over the function. The preparser verifies that the functions it skips are syntactically valid, and produces all the information needed for the outer functions to be compiled correctly. When a preparsed function is later called, it is fully parsed and compiled on-demand.&lt;/p&gt;
&lt;h2 id=&quot;variable-allocation&quot;&gt;Variable allocation &lt;a class=&quot;bookmark&quot; href=&quot;#variable-allocation&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The main thing that complicates pre-parsing is variable allocation.&lt;/p&gt;
&lt;p&gt;For performance reasons, function activations are managed on the machine stack. E.g., if a function &lt;code&gt;g&lt;/code&gt; calls a function &lt;code&gt;f&lt;/code&gt; with arguments &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;2&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;a&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; b&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; c &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; a &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; b&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; c&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// The return instruction pointer of `f` now points here&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// (because when `f` `return`s, it returns here).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First the receiver (i.e. the &lt;code&gt;this&lt;/code&gt; value for &lt;code&gt;f&lt;/code&gt;, which is &lt;code&gt;globalThis&lt;/code&gt; since it’s a sloppy function call) is pushed on the stack, followed by the called function &lt;code&gt;f&lt;/code&gt;. Then arguments &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;2&lt;/code&gt; are pushed on the stack. At that point the function &lt;code&gt;f&lt;/code&gt; is called. To execute the call, we first save the state of &lt;code&gt;g&lt;/code&gt; on the stack: the “return instruction pointer” (&lt;code&gt;rip&lt;/code&gt;; what code we need to return to) of &lt;code&gt;f&lt;/code&gt; as well as the “frame pointer” (&lt;code&gt;fp&lt;/code&gt;; what the stack should look like on return). Then we enter &lt;code&gt;f&lt;/code&gt;, which allocates space for the local variable &lt;code&gt;c&lt;/code&gt;, as well as any temporary space it may need. This ensures that any data used by the function disappears when the function activation goes out of scope: it’s simply popped from the stack.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/preparser/stack-1.svg&quot; width=&quot;173&quot; height=&quot;333&quot; intrinsicsize=&quot;173x333&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Stack layout of a call to function &lt;code&gt;f&lt;/code&gt; with arguments &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, and local variable &lt;code&gt;c&lt;/code&gt; allocated on the stack.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The problem with this setup is that functions can reference variables declared in outer functions. Inner functions can outlive the activation in which they were created:&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;make_f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// ← declaration of `d`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;a&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; b&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; c &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; a &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; b &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; d&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// ← reference to `d`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; c&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; f &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;make_f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above example, the reference from &lt;code&gt;inner&lt;/code&gt; to the local variable &lt;code&gt;d&lt;/code&gt; declared in &lt;code&gt;make_f&lt;/code&gt; is evaluated after &lt;code&gt;make_f&lt;/code&gt; has returned. To implement this, VMs for languages with lexical closures allocate variables referenced from inner functions on the heap, in a structure called a “context”.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/preparser/stack-2.svg&quot; width=&quot;428&quot; height=&quot;292&quot; intrinsicsize=&quot;428x292&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Stack layout of a call to &lt;code&gt;make_f&lt;/code&gt; with the argument copied to a context allocated on the heap for later use by &lt;code&gt;inner&lt;/code&gt; that captures &lt;code&gt;d&lt;/code&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;This means that for each variable declared in a function, we need to know whether an inner function references the variable, so we can decide whether to allocate the variable on the stack or in a heap-allocated context. When we evaluate a function literal, we allocate a closure that points both to the code for the function, as well as the current context: the object that contains the variable values it may need access to.&lt;/p&gt;
&lt;p&gt;Long story short, we do need to track at least variable references in the preparser.&lt;/p&gt;
&lt;p&gt;If we’d only track references though, we would overestimate what variables are referenced. A variable declared in an outer function could be shadowed by a redeclaration in an inner function, making a reference from that inner function target the inner declaration, not the outer declaration. If we’d unconditionally allocate the outer variable in the context, performance would suffer. Hence for variable allocation to properly work with preparsing, we need to make sure that preparsed functions properly keep track of variable references as well as declarations.&lt;/p&gt;
&lt;p&gt;Top-level code is an exception to this rule. The top-level of a script is always heap-allocated, since variables are visible across scripts. An easy way to get close to a well-working architecture is to simply run the preparser without variable tracking to fast-parse top-level functions; and to use the full parser for inner functions, but skip compiling them. This is more costly than preparsing since we unnecessarily build up an entire AST, but it gets us up and running. This is exactly what V8 did up to V8 v6.3 / Chrome 63.&lt;/p&gt;
&lt;h2 id=&quot;teaching-the-preparser-about-variables&quot;&gt;Teaching the preparser about variables &lt;a class=&quot;bookmark&quot; href=&quot;#teaching-the-preparser-about-variables&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Tracking variable declarations and references in the preparser is complicated because in JavaScript it isn’t always clear from the start what the meaning of a partial expression is. E.g., suppose we have a function &lt;code&gt;f&lt;/code&gt; with a parameter &lt;code&gt;d&lt;/code&gt;, which has an inner function &lt;code&gt;g&lt;/code&gt; with an expression that looks like it might reference &lt;code&gt;d&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; a &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; d &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It could indeed end up referencing &lt;code&gt;d&lt;/code&gt;, because the tokens we saw are part of a destructuring assignment expression.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; a &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; d &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; d&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;42&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; a&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; g&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It could also end up being an arrow function with a destructuring parameter &lt;code&gt;d&lt;/code&gt;, in which case the &lt;code&gt;d&lt;/code&gt; in &lt;code&gt;f&lt;/code&gt; isn’t referenced by &lt;code&gt;g&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token function-variable function&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; d &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; d&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; a&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;d&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; g&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Initially our preparser was implemented as a standalone copy of the parser without too much sharing, which caused the two parsers to diverge over time. By rewriting the parser and preparser to be based on a &lt;code&gt;ParserBase&lt;/code&gt; implementing the &lt;a href=&quot;https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern&quot;&gt;curiously recurring template pattern&lt;/a&gt;, we managed to maximize sharing while keeping the performance benefits of separate copies. This greatly simplified adding full variable tracking to the preparser, since a large part of the implementation can be shared between the parser and the preparser.&lt;/p&gt;
&lt;p&gt;Actually it was incorrect to ignore variable declarations and references even for top-level functions. The ECMAScript spec requires various types of variable conflicts to be detected upon first parse of the script. E.g., if a variable is twice declared as a lexical variable in the same scope, that is considered an &lt;a href=&quot;https://tc39.es/ecma262/#early-error&quot;&gt;early &lt;code&gt;SyntaxError&lt;/code&gt;&lt;/a&gt;. Since our preparser simply skipped over variable declarations, it would incorrectly allow the code during preparse. At the time we considered that the performance win warranted the spec violation. Now that the preparser tracks variables properly, however, we eradicated this entire class of variable resolution-related spec violations at no significant performance cost.&lt;/p&gt;
&lt;h2 id=&quot;skipping-inner-functions&quot;&gt;Skipping inner functions &lt;a class=&quot;bookmark&quot; href=&quot;#skipping-inner-functions&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, when a preparsed function is called for the first time, we parse it fully and compile the resulting AST to bytecode.&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// This is the top-level scope.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;outer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// preparsed&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token comment&quot;&gt;// preparsed&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token function&quot;&gt;outer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Fully parses and compiles `outer`, but not `inner`.&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function directly points to the outer context which contains the values of variable declarations that need to be available to inner functions. To allow lazy compilation of functions (and to support the debugger), the context points to a metadata object called &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/objects/scope-info.h?rcl=ce2242080787636827dd629ed5ee4e11a4368b9e&amp;amp;l=36&quot;&gt;&lt;code&gt;ScopeInfo&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;ScopeInfo&lt;/code&gt; objects describe what variables are listed in a context. This means that while compiling inner functions, we can compute where variables live in the context chain.&lt;/p&gt;
&lt;p&gt;To compute whether or not the lazy compiled function itself needs a context, though, we need to perform scope resolution again: We need to know whether functions nested in the lazy-compiled function reference the variables declared by the lazy function. We can figure this out by re-preparsing those functions. This is exactly what V8 did up to V8 v6.3 / Chrome 63. This is not ideal performance-wise though, as it makes the relation between source size and parse cost nonlinear: we would preparse functions as many times as they are nested. In addition to natural nesting of dynamic programs, JavaScript packers commonly wrap code in “&lt;a href=&quot;https://en.wikipedia.org/wiki/Immediately_invoked_function_expression&quot;&gt;immediately-invoked function expressions&lt;/a&gt;” (IIFEs), making most JavaScript programs have multiple nesting layers.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/preparser/parse-complexity-before.svg&quot; intrinsicsize=&quot;960x540&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Each reparse adds at least the cost of parsing the function.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;To avoid the nonlinear performance overhead, we perform full scope resolution even during preparsing. We store enough metadata so we can later simply &lt;em&gt;skip&lt;/em&gt; inner functions, rather than having to re-preparse them. One way would be to store variable names referenced by inner functions. This is expensive to store and requires us to still duplicate work: we have already performed variable resolution during preparse.&lt;/p&gt;
&lt;p&gt;Instead, we serialize where variables are allocated as a dense array of flags per variable. When we lazy-parse a function, variables are recreated in the same order as the preparser saw them, and we can simply apply the metadata to the variables. Now that the function is compiled, the variable allocation metadata is not needed anymore and can be garbage-collected. Since we only need this metadata for functions that actually contain inner functions, a large fraction of all functions does not even need this metadata, significantly reducing the memory overhead.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/preparser/parse-complexity-after.svg&quot; intrinsicsize=&quot;960x540&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;By keeping track of metadata for preparsed functions we can completely skip inner functions.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The performance impact of skipping inner functions is, just like the overhead of re-preparsing inner functions, nonlinear. There are sites that hoist all their functions to the top-level scope. Since their nesting level is always 0, the overhead is always 0. Many modern sites, however, do actually deeply nest functions. On those sites we saw significant improvements when this feature launched in V8 v6.3 / Chrome 63. The main advantage is that now it doesn’t matter anymore how deeply nested the code is: any function is at most preparsed once, and fully parsed once&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn1&quot; id=&quot;fnref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/preparser/skipping-inner-functions.svg&quot; width=&quot;796&quot; height=&quot;503&quot; intrinsicsize=&quot;796x503&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Main thread and off-the-main-thread parse time, before and after launching the “skipping inner functions” optimization.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;pife&quot;&gt;Possibly-Invoked Function Expressions &lt;a class=&quot;bookmark&quot; href=&quot;#pife&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, packers often combine multiple modules in a single file by wrapping module code in a closure that they immediately call. This provides isolation for the modules, allowing them to run as if they are the only code in the script. These functions are essentially nested scripts; the functions are immediately called upon script execution. Packers commonly ship &lt;em&gt;immediately-invoked function expressions&lt;/em&gt; (IIFEs; pronounced “iffies”) as parenthesized functions: &lt;code&gt;(function(){…})()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Since these functions are immediately needed during script execution, it’s not ideal to preparse such functions. During top-level execution of the script we immediately need the function to be compiled, and we fully parse and compile the function. This means that the faster parse we did earlier to try to speed up startup is guaranteed to be an unnecessary additional cost to startup.&lt;/p&gt;
&lt;p&gt;Why don’t you simply compile called functions, you might ask? While it’s typically straight-forward for a developer to notice when a function is called, this is not the case for the parser. The parser needs to decide — before it even starts parsing a function! — whether it wants to eagerly compile the function or defer compilation. Ambiguities in the syntax make it difficult to simply fast-scan to the end of the function, and the cost quickly resembles the cost of regular preparsing.&lt;/p&gt;
&lt;p&gt;For this reason V8 has two simple patterns it recognizes as &lt;em&gt;possibly-invoked function expressions&lt;/em&gt; (PIFEs; pronounced “piffies”), upon which it eagerly parses and compiles a function:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a function is a parenthesized function expression, i.e. &lt;code&gt;(function(){…})&lt;/code&gt;, we assume it will be called. We make this assumption as soon as we see the start of this pattern, i.e. &lt;code&gt;(function&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Since V8 v5.7 / Chrome 57 we also detect the pattern &lt;code&gt;!function(){…}(),function(){…}(),function(){…}()&lt;/code&gt; generated by &lt;a href=&quot;https://github.com/mishoo/UglifyJS2&quot;&gt;UglifyJS&lt;/a&gt;. This detection kicks in as soon as we see &lt;code&gt;!function&lt;/code&gt;, or &lt;code&gt;,function&lt;/code&gt; if it immediately follows a PIFE.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since V8 eagerly compiles PIFEs, they can be used as &lt;a href=&quot;https://en.wikipedia.org/wiki/Profile-guided_optimization&quot;&gt;profile-directed feedback&lt;/a&gt;&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn2&quot; id=&quot;fnref2&quot;&gt;[2]&lt;/a&gt;&lt;/sup&gt;, informing the browser which functions are needed for startup.&lt;/p&gt;
&lt;p&gt;At a time when V8 still reparsed inner functions, some developers had noticed the impact of JS parsing on startup was pretty high. The package &lt;a href=&quot;https://github.com/nolanlawson/optimize-js&quot;&gt;&lt;code&gt;optimize-js&lt;/code&gt;&lt;/a&gt; turns functions into PIFEs based on static heuristics. At the time the package was created, this had a huge impact on load performance on V8. We’ve replicated these results by running the benchmarks provided by &lt;code&gt;optimize-js&lt;/code&gt; on V8 v6.1, only looking at minified scripts.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/preparser/eager-parse-compile-pife.svg&quot; width=&quot;979&quot; height=&quot;605&quot; intrinsicsize=&quot;979x605&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Eagerly parsing and compiling PIFEs results in slightly faster cold and warm startup (first and second page load, measuring total parse + compile + execute times). The benefit is much smaller on V8 v7.5 than it used to be on V8 v6.1 though, due to significant improvements to the parser.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Nevertheless, now that we don’t reparse inner functions anymore and since the parser has gotten much faster, the performance improvement obtained through &lt;code&gt;optimize-js&lt;/code&gt; is much reduced. The default configuration for v7.5 is in fact already much faster than the optimized version running on v6.1 was. Even on v7.5 it can still makes sense to use PIFEs sparingly for code that is needed during startup: we avoid preparse since we learn early that the function will be needed.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;optimize-js&lt;/code&gt; benchmark results don’t exactly reflect the real world. The scripts are loaded synchronously, and the entire parse + compile time is counted towards load time. In a real-world setting, you would likely load scripts using &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags. That allows Chrome’s preloader to discover the script &lt;em&gt;before&lt;/em&gt; it’s evaluated, and to download, parse, and compile the script without blocking the main thread. Everything that we decide to eagerly compile is automatically compiled off the main thread and should only minimally count towards startup. Running with off-the-main-thread script compilation magnifies the impact of using PIFEs.&lt;/p&gt;
&lt;p&gt;There is still a cost though, especially a memory cost, so it’s not a good idea to eagerly compile everything:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/preparser/eager-compilation-overhead.svg&quot; width=&quot;477&quot; height=&quot;295&quot; intrinsicsize=&quot;477x295&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;Eagerly compiling &lt;em&gt;all&lt;/em&gt; JavaScript comes at a significant memory cost.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;While adding parentheses around functions you need during startup is a good idea (e.g., based on profiling startup), using a package like &lt;code&gt;optimize-js&lt;/code&gt; that applies simple static heuristics is not a great idea. It for example assumes that a function will be called during startup if it’s an argument to a function call. If such a function implements an entire module that’s only needed much later, however, you end up compiling too much. Over-eagerly compilation is bad for performance: V8 without lazy compilation significantly regresses load time. Additionally, some of the benefits of &lt;code&gt;optimize-js&lt;/code&gt; come from issues with UglifyJS and other minifiers which remove parentheses from PIFEs that aren’t IIFEs, removing useful hints that could have been applied to e.g., &lt;a href=&quot;https://github.com/umdjs/umd&quot;&gt;Universal Module Definition&lt;/a&gt;-style modules. This is likely an issue that minifiers should fix to get the maximum performance on browsers that eagerly compile PIFEs.&lt;/p&gt;
&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions &lt;a class=&quot;bookmark&quot; href=&quot;#conclusions&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Lazy parsing speeds up startup and reduces memory overhead of applications that ship more code than they need. Being able to properly track variable declarations and references in the preparser is necessary to be able to preparse both correctly (per the spec) and quickly. Allocating variables in the preparser also allows us to serialize variable allocation information for later use in the parser so we can avoid having to re-preparse inner functions altogether, avoiding non-linear parse behavior of deeply nested functions.&lt;/p&gt;
&lt;p&gt;PIFEs that can be recognized by the parser avoid initial preparse overhead for code that’s needed immediately during startup. Careful profile-guided use of PIFEs, or use by packers, can provide a useful cold startup speed bump. Nevertheless, needlessly wrapping functions in parentheses to trigger this heuristic should be avoided since it causes more code to be eagerly compiled, resulting in worse startup performance and increased memory usage.&lt;/p&gt;
&lt;hr class=&quot;footnotes-sep&quot;&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;ol class=&quot;footnotes-list&quot;&gt;
&lt;li id=&quot;fn1&quot; class=&quot;footnote-item&quot;&gt;&lt;p&gt;For memory reasons, V8 &lt;a href=&quot;https://v8.js.cn/blog/v8-release-74#bytecode-flushing&quot;&gt;flushes bytecode&lt;/a&gt; when it’s unused for a while. If the code ends up being needed again later on, we reparse and compile it again. Since we allow the variable metadata to die during compilation, that causes a reparse of inner functions upon lazy recompilation. At that point we recreate the metadata for its inner functions though, so we don’t need to re-preparse inner functions of its inner functions again. &lt;a href=&quot;#fnref1&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;fn2&quot; class=&quot;footnote-item&quot;&gt;&lt;p&gt;PIFEs can also be thought of as profile-informed function expressions. &lt;a href=&quot;#fnref2&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content></entry><entry><title>给 JavaScript 开发者的代码缓存指南</title><link href="https://v8.js.cn/blog/code-caching-for-devs/"/><updated>2019-04-08T13:33:37+00:00</updated><id>https://v8.js.cn/blog/code-caching-for-devs/</id><author><name>Leszek Swirski, cache smasher</name></author><content type="html">&lt;p&gt;代码缓存（也被称为字节码缓存）是浏览器的一个重要优化手段。它通过缓存解析+编译后的结果来提升高频访问网站的启动速度。&lt;a href=&quot;https://blog.mozilla.org/javascript/2017/12/12/javascript-startup-bytecode-cache/&quot;&gt;大多数&lt;/a&gt;的主流&lt;a href=&quot;https://bugs.webkit.org/show_bug.cgi?id=192782&quot;&gt;浏览器&lt;/a&gt;都实现了代码缓存，Chrome 也不例外。事实上，关于 Chrome 和 V8 缓存编译后代码的实现，之前我们已经写文章（[Code caching](/blog/code-caching、&lt;a href=&quot;https://v8.js.cn/blog/improved-code-caching&quot;&gt;改进代码缓存&lt;/a&gt;）也做过&lt;a href=&quot;https://www.youtube.com/watch?v=YqHOUy2rYZ8&quot;&gt;演讲&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在这篇文章中，我们将为那些想要更好的利用代码缓存来提高网站启动速度的 JS 开发者提供一些建议。这些建议集中在 Chrome/V8 的代码缓存实现上，但是其他大多数浏览器实现原理基本也是这样的。&lt;/p&gt;
&lt;h2 id=&quot;code-caching-recap&quot;&gt;代码缓存回顾 &lt;a class=&quot;bookmark&quot; href=&quot;#code-caching-recap&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;虽然其他文章和演讲已经提供代码缓存实现的详细信息，但是我们仍然要快速回顾下它是如何工作的，对于 V8 编译后的代码 Chrome 有两级缓存：一个是由 V8（&lt;code&gt;Isolate&lt;/code&gt; 缓存）维护的低成本的“尽力而为”内存缓存和一个完整序列化的硬盘缓存。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Isolate&lt;/code&gt; 缓存操作发生在同一个 V8 Isolate 中编译的脚本（即同一个进程，简单来说就是“在同一个 tab 页中导航的相同页面” ）。它是“尽力而为”，因为它试图尽可能快而小地使用已经可用的数据，以牺牲潜在的低命中率和跨进程的缓存为代价。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当 V8 编译脚本时，编译后的脚本以源码为键被存储在一个 hashtable 中（在 V8 的堆中）。&lt;/li&gt;
&lt;li&gt;当 Chrome 要求 V8 变异其他脚本的时候，V8 首先检查脚本的源码是否能匹配 hashtable 中的值。如果是，则返回已经存在的字节码。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Isolate 缓存是快速且高效的，目前我们检测到在真实情况中它的命中率达到 80% 。&lt;/p&gt;
&lt;p&gt;硬盘代码缓存是由 Chrome 管理（准确来说是由 Blink ），它填充了 &lt;code&gt;Isolate&lt;/code&gt; 缓存不能在多个进程或多个 Chrome 会话间共享代码缓存的空白。它利用现有的 HTTP 资源缓存，该缓存管理从 Web 接收的缓存和过期数据。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首次请求 JS 文件（即 &lt;em&gt;cold run&lt;/em&gt;）时，Chrome 会下载并将其提供给 V8 进行编译。它还将文件存储在浏览器的磁盘缓存中。&lt;/li&gt;
&lt;li&gt;当第二次请求 JS 文件（即 &lt;em&gt;warm run&lt;/em&gt;）时，Chrome 从浏览器缓存中获取文件并再次将其提供给 V8 进行编译。但是，这次编译的代码被序列化，并作为元数据附加到缓存的脚本文件。&lt;/li&gt;
&lt;li&gt;第三次（即 &lt;em&gt;hot run&lt;/em&gt;），Chrome 从缓存中获取文件和文件的元数据，并将两者都交给 V8。V8 反序列化元数据，可以跳过编译。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;综上，&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/overview.svg&quot; intrinsicsize=&quot;487x280&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;代码缓存被分为冷运行、暖运行和热运行，在内存缓存发生在暖运行，硬盘缓存发生在热运行&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;基于这段描述，我们可以提供最好的建议来提高你的网站对代码缓存的利用。&lt;/p&gt;
&lt;h2 id=&quot;do-nothing&quot;&gt;提示 1：什么都不要做 &lt;a class=&quot;bookmark&quot; href=&quot;#do-nothing&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;理想情况见，做为 JS 开发者为了提高代码的缓存能做的最好的事情就是“什么也不做”。这实际上有两层含义，一是被动的不做，二是主动的不做。&lt;/p&gt;
&lt;p&gt;代码缓存终究是浏览器实现的细节。基于启发式的数据与空间的权衡性能优化，它的实现和启发式可能定期变化。做为 V8 工程师，我们会尽我们所能使启发式适用于在不断发展的 Web 中的每一个人，而且对当前代码缓存实现细节的过度的优化可能会在一些版本发布后，当这些细节改变后引起失望。另外，其他的一些 JavaScript 引擎可能使用了不同的启发式实现代码缓存。因此从各方面来说，对于使用代码缓存我们最好的建议是：书写整洁且符合习惯的代码，而且我们会尽可能的优化它。&lt;/p&gt;
&lt;p&gt;除了被动不做什么，你应该尽可能地主动不做什么。任何形式的缓存内在都依赖于事物没有改变，因此什么都不做是允许缓存数据保持缓存的最佳方式。这儿有几个你什么都不做的方法。&lt;/p&gt;
&lt;h3 id=&quot;don’t-change-code&quot;&gt;不要改变代码 &lt;a class=&quot;bookmark&quot; href=&quot;#don’t-change-code&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;这也许是显而易见的事情，但是仍然值得明确说明———当你上线一份新的代码的时候，代码还没有被缓存。当浏览器通过 HTTP 请求一个脚本 URL 的时候，它包含了上次请求 URL 的时间，如果服务器知道文件没有改变，它返回 304 Not Modified 响应，维持我们的代码缓存热运行状态。否则，返回 200 OK 响应更新缓存资源，并且清除代码缓存，恢复到冷运行状态。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/http-200-vs-304.jpg&quot; intrinsicsize=&quot;600x515&quot; alt=&quot;&quot; title=&quot;Drake 更加喜欢 HTTP 响应状态码为 304，而不是 HTTP 200&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;它总是立即推送你最新的代码更改，特使是如果你想要衡量某次更改的影响的时候，但是对于缓存来说，最好是保留代码或尽可能地减少更新。可以考虑限制每周的上限次数 &lt;code&gt;≤ x&lt;/code&gt;，&lt;code&gt;x&lt;/code&gt; 是你调整权衡缓存与陈旧性的滑块。&lt;/p&gt;
&lt;h3 id=&quot;don’t-change-urls&quot;&gt;不要改变 URL &lt;a class=&quot;bookmark&quot; href=&quot;#don’t-change-urls&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;代码缓存与脚本的 URL 存在关联，这是为了便于检查而无需查看实际的脚本内容。这意味着改变脚本的 URL（包括改变请求查询参数） 会在我们的缓存资源中创建一个新的资源入口，并伴随着一个冷缓存入口。&lt;/p&gt;
&lt;p&gt;当然，这可以被用来强制清除缓存，尽管那也是一个实现细节。也许有一天我们会使用源文件内容关联缓存而不是源文件的 URL，那么这个建议将不在有效。&lt;/p&gt;
&lt;h3 id=&quot;don’t-change-execution-behavior&quot;&gt;不要改变代码执行行为 &lt;a class=&quot;bookmark&quot; href=&quot;#don’t-change-execution-behavior&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;对代码缓存实现的最新优化之一是&lt;a href=&quot;https://v8.js.cn/blog/improved-code-caching#increasing-the-amount-of-code-that-is-cached&quot;&gt;仅在编译后的代码执行后对其进行序列化&lt;/a&gt;。 这是为了尝试捕获延迟编译的函数，这些函数仅在执行期间编译，而不是在初始编译期间编译。&lt;/p&gt;
&lt;p&gt;当每次执行脚本执行相同的代码或至少相同的函数时，这个优化最有效。 如果你进行 A/B 测试，且测试取决于运行时决策，这样做可能会有问题：&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Math&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token constant&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token constant&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这个例子中，仅 &lt;code&gt;A()&lt;/code&gt; 或 &lt;code&gt;B()&lt;/code&gt; 被编译或执行在热运行时，并进入到代码缓存，另外一个可能会在后续的代码运行中被执行。相反，保持运行时的确定性，以保持其在缓存路径上。&lt;/p&gt;
&lt;h2 id=&quot;do-something&quot;&gt;提示 2: 做一些事情 &lt;a class=&quot;bookmark&quot; href=&quot;#do-something&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;当然无论是被动还是主动“什么都不做”的建议都不能让人满意。因此除了“什么都不做”，鉴于我们目前的启发式和实现，你可以做一些事情。请记住，启发式和建议都可能改变，且没有一个代替分析。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/with-great-power.jpg&quot; intrinsicsize=&quot;500x209&quot; alt=&quot;&quot; title=&quot;Uncle Ben suggests that Peter Parker should be cautious when optimizing his web app’s cache behavior.&quot;&gt;
&lt;/figure&gt;
&lt;h3 id=&quot;split&quot;&gt;将库从使用代码中分离 &lt;a class=&quot;bookmark&quot; href=&quot;#split&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;代码缓存粗略的在每个脚本上完成，意味着脚本的每一部分改动都会导致整个脚本的缓存失效。如果你将稳定的部分和经常变动的部分放在一个脚本文件中，例如：库和业务逻辑，业务逻辑代码的改变会使库代码的缓存也无效。&lt;/p&gt;
&lt;p&gt;因此，你可以分离稳定的库代码到一个单独的脚本，且单独的加载它。这样库代码一旦被缓存，并在业务逻辑代码改变的时候保持缓存。&lt;/p&gt;
&lt;p&gt;如果你的库在你网站的不同的页面被共享，这样做还有其他的收益：由于代码缓存附加到脚本，因此库的代码换在也在页面之间共享。&lt;/p&gt;
&lt;h3 id=&quot;merge&quot;&gt;合并库文件到使用它们的代码中 &lt;a class=&quot;bookmark&quot; href=&quot;#merge&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;代码缓存在每个脚本执行后完成，意味着一个脚本的代码缓存包含了当脚本执行完编译后的那些函数。这对库代码有几个重要意义：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;代码缓存不包含早期脚本中的函数。&lt;/li&gt;
&lt;li&gt;代码缓存不包含后续脚本调用的延迟编译的函数。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;特别是，如果一个库完全由延迟编译的函数组成，那么即使稍后使用他们也不会缓存这些函数。&lt;/p&gt;
&lt;p&gt;对此一个解决方案是合并库和使用它们的代码到单个脚本中，以至于代码缓存可以“发现”库的那些部分被使用。不幸的是，这与上一条建议相违背，因为没有银弹。通常来说，我们不建议将所有 JS 脚本合并到一个大的 bundle 中，将其分成多个较小脚本往往更有利于除代码缓存之外的其他原因（如：多个网络请求、流编译、页面交互等）。&lt;/p&gt;
&lt;h3 id=&quot;iife&quot;&gt;利用启发式 IIFE &lt;a class=&quot;bookmark&quot; href=&quot;#iife&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;只有在代码执行完成时编译的代码才会被加入到代码缓存，因此有许多类型的函数尽管稍后执行，但不会被缓存。事件处理程序（甚至是 &lt;code&gt;onload&lt;/code&gt;）、promise 链、未使用的库函数和其他一些延迟编译而没有在执行到 &lt;code&gt;&amp;lt;/script&amp;gt;&lt;/code&gt; 之前被调用的，都会保持延迟而不会被执行。&lt;/p&gt;
&lt;p&gt;一种方法强制这些函数被缓存就是强制它们被编译，且一个常用的强制编译方法是使用 IIFE 启发式。IIFE（立即执行函数表达式）是一种创建函数后立即点用函数的模式。&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// …&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因为 IIFE 表达式会被立即调用，为了避免支付延迟编译的成本，大多数 JavaScript 引擎会尝试探测它们并立即编译，然后进行完全编译。有各种启发式可以尽早探测出 IIFE 表达式（在函数被解析之前），最常用的是通过 &lt;code&gt;function&lt;/code&gt; 关键字之前的 &lt;code&gt;(&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;因为这个启发式在早期被应用，所以即使函数实际不是立即执行也会被编译：&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token function-variable function&quot;&gt;foo&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// Lazily skipped&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token function-variable function&quot;&gt;bar&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token comment&quot;&gt;// Eagerly compiled&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这意味着可以通过将那些应该被缓存的函数包裹在括号里强制加入到缓存中。但是，如果不正确的使用，可能会对网页启动时间产生影响，通常来说这有点滥用启发式，因此除非真的有必要，我们不建议这么做。&lt;/p&gt;
&lt;h3 id=&quot;group&quot;&gt;合并小文件 &lt;a class=&quot;bookmark&quot; href=&quot;#group&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Chrome 有个代码缓存的最小文件大小限制，现在是 &lt;a href=&quot;https://cs.chromium.org/chromium/src/third_party/blink/renderer/bindings/core/v8/v8_code_cache.cc?l=91&amp;amp;rcl=2f81d000fdb5331121cba7ff81dfaaec25b520a5&quot;&gt;1 Kib&lt;/a&gt; 。这意味着小于 1 Kib 的脚本不能被缓存，因为我们认为开销大于收益。&lt;/p&gt;
&lt;p&gt;如果你的网站有很多小的脚本，则开销计算可能不在以相同的方式进行。你应该考虑合并小文件使它们超出最小代码大小，并从常规的减少脚本开销的方式受益。&lt;/p&gt;
&lt;h3 id=&quot;avoid-inline-scripts&quot;&gt;避免使用内联脚本 &lt;a class=&quot;bookmark&quot; href=&quot;#avoid-inline-scripts&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;HTML 中的内联脚本没有关联外部的源文件，因此不能被上述机制缓存。Chrome 尝试通过将它们附加 HTML 文档资源缓存，但是这些缓存依赖于&lt;strong&gt;整个&lt;/strong&gt; HTML 文档没有变化，且不能在页面间共享。&lt;/p&gt;
&lt;p&gt;因此，对于可以从代码缓存中受益的脚本，请避免将它们内联到 HTML 中，而是推荐将它们包含在外部文件中。&lt;/p&gt;
&lt;h3 id=&quot;use-service-worker-caches&quot;&gt;使用 service worker 缓存 &lt;a class=&quot;bookmark&quot; href=&quot;#use-service-worker-caches&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;service worker 是一种让你的代码可以拦截你页面中的网络资源请求的一种机制。特别是，它们可以让你构建本地资源缓存，当你发送请求的时候，会从本地缓存提供资源。如果你想构建离线应用这点特别有用，例如：PWA 应用。&lt;/p&gt;
&lt;p&gt;一个典型的栗子，网站使用 service worker 在主脚本中注册 service worker：&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// main.mjs&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;navigator&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;serviceWorker&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;register&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;/sw.js&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;service worker 为安装（创建资源）和获取（从潜在的缓存提供资源）事件添加处理程序。&lt;/p&gt;
&lt;pre class=&quot;language-js&quot;&gt;&lt;code class=&quot;language-js&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// sw.js&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;addEventListener&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;install&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token parameter&quot;&gt;event&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;buildCache&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; cache &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;await&lt;/span&gt; caches&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;cacheName&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; cache&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;addAll&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;/main.css&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;/main.mjs&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;/offline.html&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;waitUntil&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;buildCache&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;addEventListener&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;fetch&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token parameter&quot;&gt;event&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token keyword&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;cachedFetch&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token parameter&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; cache &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;await&lt;/span&gt; caches&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;cacheName&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;let&lt;/span&gt; response &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;await&lt;/span&gt; cache&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;request&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;response&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; response&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    response &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;request&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    cache&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;request&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; response&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; response&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;  event&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;respondWith&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;cachedFetch&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;event&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这些缓存包括 JS 资源缓存。然而，因为我们希望 service worker 的缓存主要用于 PWA，所以它与 Chrome 的“自动”缓存的启发式有略微不同。首先，当 JS 资源被添加到缓存的时候，它们立即创建代码缓存，这意味着在第二次加载的时候代码缓存是可用的（而不是像普通缓存一样仅在第三次加载的时可用）。其次，我们为这些脚本生成了“全量”代码缓存，不在有延迟编译，而是全部编译好放到缓存中。这具有快速且可预测的性能的优点，没有执行顺序依赖性，但是以增加的内存使用为代价。请注意，此启发式仅适用于 service worker 缓存，而不适用于 &lt;code&gt;Cache&lt;/code&gt; API 的其他用途。实际上，当在 service worker 外面使用时，现在的 &lt;code&gt;Cache&lt;/code&gt; API 不会执行代码缓存。&lt;/p&gt;
&lt;h2 id=&quot;tracing&quot;&gt;Tracing &lt;a class=&quot;bookmark&quot; href=&quot;#tracing&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;上面的那些建议都不能保证提升你 web 应用的速度。不幸的是，代码缓存信息现在还没有暴露到 Devtool 中，因此最可靠的方式去查看你 web 应用的脚本缓存是使用 &lt;code&gt;chrome://tracing&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;chrome://tracing&lt;/code&gt; 记录了一段时间内的 Chrome 追踪信息，它生成的追踪结果可视化如下：&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-visualization.png&quot; srcset=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-visualization@2x.png 2x&quot; intrinsicsize=&quot;722x672&quot; alt=&quot;&quot;&gt;
  &lt;figcaption&gt;&lt;code&gt;chrome://tracing&lt;/code&gt; UI 记录了一次 warm cache 执行情况&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Tracing 记录着整个浏览器的行为，包含其他 tab、窗口和扩展程序，因此最好在干净的用户配置——没有其他扩展程序安装且没有其他 tab 页打开的时候，完成分析：&lt;/p&gt;
&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;highlight-line&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# 开始一次干净的用户配置的 Chrome 浏览会话&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;highlight-line&quot;&gt;google-chrome --user-data-dir&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;&lt;span class=&quot;token variable&quot;&gt;&lt;span class=&quot;token variable&quot;&gt;$(&lt;/span&gt;mktemp -d&lt;span class=&quot;token variable&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&quot;&lt;/span&gt; --disable-extensions&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当收集追踪信息时，你需要选中追踪类别。在大多数情况下，你可以简单的选中 &amp;quot;web developer&amp;quot; 这个类别，但你也可以手动选择类别。代码追踪的重要类别是 &lt;code&gt;v8&lt;/code&gt;。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-categories-1.png&quot; srcset=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-categories-1@2x.png 2x&quot; intrinsicsize=&quot;721x607&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-categories-2.png&quot; srcset=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-categories-2@2x.png 2x&quot; intrinsicsize=&quot;721x607&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;当记录了一次 &lt;code&gt;v8&lt;/code&gt; 类别的追踪时，在追踪结果中查看 &lt;code&gt;v8.compile&lt;/code&gt; 片段（或者你可以都搜索框中输入 &lt;code&gt;v8.compile&lt;/code&gt;）。它会列出编译后的文件，已经编译的元数据。&lt;/p&gt;
&lt;p&gt;在脚本 cold run 时，是没有代码缓存是信息的，这就意味着脚本不参与生成或使用缓存数据。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-cold-run.png&quot; srcset=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-cold-run@2x.png 2x&quot; intrinsicsize=&quot;405x318&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;在 warm run 时，每个脚本有两个 &lt;code&gt;v8.compile&lt;/code&gt; 入口：一个是实际编译，另一个（在执行后）是为了产生缓存。你可以通过它是否有 &lt;code&gt;cacheProduceOptions&lt;/code&gt; 和 &lt;code&gt;producedCacheSize&lt;/code&gt; 两个元数据字段来判断。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-warm-run.png&quot; srcset=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-warm-run@2x.png 2x&quot; intrinsicsize=&quot;404x386&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;在 hot run 时，你将看到一个用于消费缓存的 &lt;code&gt;v8.compile&lt;/code&gt; 入口，有 &lt;code&gt;cacheConsumeOptions&lt;/code&gt; 和 &lt;code&gt;consumedCacheSize&lt;/code&gt; 两个元数据字段。所有大小都以字节表示。&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-hot-run.png&quot; srcset=&quot;https://v8.js.cn/_img/code-caching-for-devs/chrome-tracing-hot-run@2x.png 2x&quot; intrinsicsize=&quot;406x363&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;总结 &lt;a class=&quot;bookmark&quot; href=&quot;#conclusion&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;对于大多数开发人员来说，代码缓存应该“正常工作”。当事物保持不变时，它就像任何缓存一样工作得最好，并且它工作在不同版本可以发生变化的启发式方法上。 尽管如此，代码缓存确实具有可以使用的行为，可以避免的限制以及使用 &lt;code&gt;chrome://tracing&lt;/code&gt; 的仔细分析可以帮助你调整和优化 Web 应用程序对缓存的使用。&lt;/p&gt;
</content></entry><entry><title>Blazingly fast parsing, part 1: optimizing the scanner</title><link href="https://v8.js.cn/blog/scanner/"/><updated>2019-03-25T13:33:37+00:00</updated><id>https://v8.js.cn/blog/scanner/</id><author><name>Toon Verwaest (@tverwaes), scandalous optimizer</name></author><content type="html">&lt;p&gt;To run a JavaScript program, the source text needs to be processed so V8 can understand it. V8 starts out by parsing the source into an abstract syntax tree (AST), a set of objects that represent the program structure. That AST gets compiled to bytecode by Ignition. The performance of these parse + compile phases is important: V8 cannot run code before compilation is done. In this series of blog posts, we focus on parsing, and the work done in V8 to ship a blazingly fast parser.&lt;/p&gt;
&lt;p&gt;In fact, we start the series one stage before the parser. V8’s parser consumes ‘tokens’ provided by the ‘scanner’. Tokens are blocks of one or more characters that have a single semantic meaning: a string, an identifier, an operator like &lt;code&gt;++&lt;/code&gt;. The scanner constructs these tokens by combining consecutive characters in an underlying character stream.&lt;/p&gt;
&lt;p&gt;The scanner consumes a stream of Unicode characters. These Unicode characters are always decoded from a stream of UTF-16 code units. Only a single encoding is supported to avoid branching or specializing the scanner and parser for various encodings, and we chose UTF-16 since that’s the encoding of JavaScript strings, and source positions need to be provided relative to that encoding. The &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/scanner.h?rcl=edf3dab4660ed6273e5d46bd2b0eae9f3210157d&amp;amp;l=46&quot;&gt;&lt;code&gt;UTF16CharacterStream&lt;/code&gt;&lt;/a&gt; provides a (possibly buffered) UTF-16 view over the underlying Latin1, UTF-8, or UTF-16 encoding that V8 receives from Chrome, which Chrome in turn received from the network. In addition to supporting more than one encoding, the separation between scanner and character stream allows V8 to transparently scan as if the entire source is available, even though we may only have received a portion of the data over the network so far.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/scanner/overview.svg&quot; intrinsicsize=&quot;873x424&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;The interface between the scanner and the character stream is a method named &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/scanner.h?rcl=edf3dab4660ed6273e5d46bd2b0eae9f3210157d&amp;amp;l=54&quot;&gt;&lt;code&gt;Utf16CharacterStream::Advance()&lt;/code&gt;&lt;/a&gt; that returns either the next UTF-16 code unit, or &lt;code&gt;-1&lt;/code&gt; to flag end of input. UTF-16 cannot encode every Unicode character in a single code unit. Characters outside the &lt;a href=&quot;https://en.wikipedia.org/wiki/Plane_(Unicode)#Basic_Multilingual_Plane&quot;&gt;Basic Multilingual Plane&lt;/a&gt; are encoded as two code units, also called surrogate pairs. The scanner operates on Unicode characters rather than UTF-16 code units though, so it wraps this low-level stream interface in a &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/scanner.h?sq=package:chromium&amp;amp;g=0&amp;amp;rcl=edf3dab4660ed6273e5d46bd2b0eae9f3210157d&amp;amp;l=569&quot;&gt;&lt;code&gt;Scanner::Advance()&lt;/code&gt;&lt;/a&gt; method that decodes UTF-16 code units into full Unicode characters. The currently decoded character is buffered and picked up by scan methods, such as &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/scanner.cc?rcl=edf3dab4660ed6273e5d46bd2b0eae9f3210157d&amp;amp;l=775&quot;&gt;&lt;code&gt;Scanner::ScanString()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The scanner &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/scanner.cc?rcl=edf3dab4660ed6273e5d46bd2b0eae9f3210157d&amp;amp;l=422&quot;&gt;chooses&lt;/a&gt; a specific scanner method or token based on a maximum lookahead of 4 characters, the longest ambiguous sequence of characters in JavaScript&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn1&quot; id=&quot;fnref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;. Once a method like &lt;code&gt;ScanString&lt;/code&gt; is chosen, it consumes the remainder of characters for that token, buffering the first character that’s not part of the token for the next scanned token. In the case of &lt;code&gt;ScanString&lt;/code&gt; it also copies the scanned characters into a buffer encoded as Latin1 or UTF-16, while decoding escape sequences.&lt;/p&gt;
&lt;h2 id=&quot;whitespace&quot;&gt;Whitespace &lt;a class=&quot;bookmark&quot; href=&quot;#whitespace&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Tokens can be separated by various types of whitespace, e.g., newline, space, tab, single line comments, multiline comments, etc. One type of whitespace can be followed by other types of whitespace. Whitespace adds meaning if it causes a line break between two tokens: that possibly results in &lt;a href=&quot;https://tc39.es/ecma262/#sec-automatic-semicolon-insertion&quot;&gt;automatic semicolon insertion&lt;/a&gt;. So before scanning the next token, all whitespace is skipped keeping track of whether a newline occured. Most real-world production JavaScript code is minified, and so multi-character whitespace luckily isn’t very common. For that reason V8 uniformly scans each type of whitespace independently as if they were regular tokens. E.g., if the first token character is &lt;code&gt;/&lt;/code&gt; followed by another &lt;code&gt;/&lt;/code&gt;, V8 scans this as a single-line comment which returns &lt;code&gt;Token::WHITESPACE&lt;/code&gt;. That loop simply continues scanning tokens &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/scanner.cc?rcl=edf3dab4660ed6273e5d46bd2b0eae9f3210157d&amp;amp;l=671&quot;&gt;until&lt;/a&gt; we find a token other than &lt;code&gt;Token::WHITESPACE&lt;/code&gt;. This means that if the next token is not preceded by whitespace, we immediately start scanning the relevant token without needing to explicitly check for whitespace.&lt;/p&gt;
&lt;p&gt;The loop itself however adds overhead to each scanned token: it requires a branch to verify the token that we’ve just scanned. It would be better to continue the loop only if the token we have just scanned could be a &lt;code&gt;Token::WHITESPACE&lt;/code&gt;. Otherwise we should just break out of the loop. We do this by moving the loop itself into a separate &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/parsing/scanner-inl.h?rcl=d62ec0d84f2ec8bc0d56ed7b8ed28eaee53ca94e&amp;amp;l=178&quot;&gt;helper method&lt;/a&gt; from which we return immediately when we’re certain the token isn’t &lt;code&gt;Token::WHITESPACE&lt;/code&gt;. Even though these kinds of changes may seem really small, they remove overhead for each scanned token. This especially makes a difference for really short tokens like punctuation:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/scanner/punctuation.svg&quot; intrinsicsize=&quot;464x287&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;identifier-scanning&quot;&gt;Identifier scanning &lt;a class=&quot;bookmark&quot; href=&quot;#identifier-scanning&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The most complicated, but also most common token, is the &lt;a href=&quot;https://tc39.es/ecma262/#prod-Identifier&quot;&gt;identifier&lt;/a&gt; token, which is used for variable names (among other things) in JavaScript. Identifiers start with a Unicode character with the property &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/unicode.cc?rcl=d4096d05abfc992a150de884c25361917e06c6a9&amp;amp;l=807&quot;&gt;&lt;code&gt;ID_Start&lt;/code&gt;&lt;/a&gt;, optionally followed by a sequence of characters with the property &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/unicode.cc?rcl=d4096d05abfc992a150de884c25361917e06c6a9&amp;amp;l=947&quot;&gt;&lt;code&gt;ID_Continue&lt;/code&gt;&lt;/a&gt;. Looking up whether a Unicode character has the property &lt;code&gt;ID_Start&lt;/code&gt; or &lt;code&gt;ID_Continue&lt;/code&gt; is quite expensive. By inserting a cache mapping from characters to their properties we can speed this up a bit.&lt;/p&gt;
&lt;p&gt;Most JavaScript source code is written using ASCII characters though. Of the ASCII-range characters, only &lt;code&gt;a-z&lt;/code&gt;, &lt;code&gt;A-Z&lt;/code&gt;, &lt;code&gt;$&lt;/code&gt; and &lt;code&gt;_&lt;/code&gt; are identifier start characters. &lt;code&gt;ID_Continue&lt;/code&gt; additionally includes &lt;code&gt;0-9&lt;/code&gt;. We speed up identifier scanning by building a table with flags for each of the 128 ASCII characters indicating whether the character is an &lt;code&gt;ID_Start&lt;/code&gt;, an &lt;code&gt;ID_Continue&lt;/code&gt; character, etc. While characters we’re looking at are within ASCII range, we look up the respective flags in this table and verify a property with a single branch. Characters are part of the identifier until we see the first character that does not have the &lt;code&gt;ID_Continue&lt;/code&gt; property.&lt;/p&gt;
&lt;p&gt;All the improvements mentioned in this post add up to the following difference in identifier scanning performance:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/scanner/identifiers-1.svg&quot; intrinsicsize=&quot;600x371&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;It may seem counterintuitive that longer identifiers scan faster. That might make you think that it’s beneficial for performance to increase the identifier length. Scanning longer identifiers is simply faster in terms of MB/s because we stay longer in a very tight loop without returning to the parser. What you care about from the point-of-view of the performance of your application, however, is how fast we can scan full tokens. The following graph roughly shows the number of tokens we scan per second relative to the token length:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/scanner/identifiers-2.svg&quot; intrinsicsize=&quot;600x371&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;Here it becomes clear that using shorter identifiers is beneficial for the parse performance of your application: we’re able to scan more tokens per second. This means that sites that we seem to parse faster in MB/s simply have lower information density, and actually produce fewer tokens per second.&lt;/p&gt;
&lt;h2 id=&quot;internalizing-minified-identifiers&quot;&gt;Internalizing minified identifiers &lt;a class=&quot;bookmark&quot; href=&quot;#internalizing-minified-identifiers&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All string literals and identifiers are deduplicated on the boundary between the scanner and the parser. If the parser requests the value of a string or identifier, it receives a unique string object for each possible literal value. This typically requires a hash table lookup. Since JavaScript code is often minified, V8 uses a simple lookup table for single ASCII character strings.&lt;/p&gt;
&lt;h2 id=&quot;keywords&quot;&gt;Keywords &lt;a class=&quot;bookmark&quot; href=&quot;#keywords&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Keywords are a special subset of identifiers defined by the language, e.g., &lt;code&gt;if&lt;/code&gt;, &lt;code&gt;else&lt;/code&gt;, and &lt;code&gt;function&lt;/code&gt;. V8’s scanner returns different tokens for keywords than for identifiers. After scanning an identifier we need to recognize whether the identifier is a keyword. Since all keywords in JavaScript only contain lowercase characters &lt;code&gt;a-z&lt;/code&gt;, we also keep flags indicating whether ASCII characters are possible keyword start and continue characters.&lt;/p&gt;
&lt;p&gt;If an identifier can be a keyword according to the flags, we could find a subset of keyword candidates by switching over the first character of the identifier. There are more distinct first characters than lengths of keywords, so it reduces the number of subsequent branches. For each character, we branch based on the possible keyword lengths and only compare the identifier with the keyword if the length matches as well.&lt;/p&gt;
&lt;p&gt;Better is to use a technique called &lt;a href=&quot;https://en.wikipedia.org/wiki/Perfect_hash_function&quot;&gt;perfect hashing&lt;/a&gt;. Since the list of keywords is static, we can compute a perfect hash function that for each identifier gives us at most one candidate keyword. V8 uses &lt;a href=&quot;https://www.gnu.org/software/gperf/&quot;&gt;gperf&lt;/a&gt; to compute this function. The &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/parsing/keywords-gen.h&quot;&gt;result&lt;/a&gt; computes a hash from the length and first two identifier characters to find the single candidate keyword. We only compare the identifier with the keyword if the length of that keyword matches the input identifier length. This especially speeds up the case where an identifier isn’t a keyword since we need fewer branches to figure it out.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/scanner/keywords.svg&quot; intrinsicsize=&quot;545x336&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;surrogate-pairs&quot;&gt;Surrogate pairs &lt;a class=&quot;bookmark&quot; href=&quot;#surrogate-pairs&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, our scanner operates on a UTF-16 encoded stream of characters, but consumes Unicode characters. Characters in supplementary planes only have a special meaning for identifier tokens. If for example such characters occur in a string, they do not terminate the string. Lone surrogates are supported by JS and are simply copied from the source as well. For that reason it is better to avoid combining surrogate pairs until absolutely necessary, and let the scanner operate directly on UTF-16 code units instead of Unicode characters. When we are scanning a string, we do not need to look for surrogate pairs, combine them, and then later split them again when we stash away the characters to build up a literal. There are only two remaining places where the scanner does need to deal with surrogate pairs. At the start of token scanning, only when we don’t recognize a character as anything else do we need to &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/parsing/scanner-inl.h?rcl=d4096d05abfc992a150de884c25361917e06c6a9&amp;amp;l=515&quot;&gt;combine&lt;/a&gt; surrogate pairs to check whether the result is an identifier start. Similarly, we need to &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/parsing/scanner.cc?rcl=d4096d05abfc992a150de884c25361917e06c6a9&amp;amp;l=1003&quot;&gt;combine&lt;/a&gt; surrogate pairs in the slow path of identifier scanning dealing with non-ASCII characters.&lt;/p&gt;
&lt;h2 id=&quot;advanceuntil&quot;&gt;&lt;code&gt;AdvanceUntil&lt;/code&gt; &lt;a class=&quot;bookmark&quot; href=&quot;#advanceuntil&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The interface between the scanner and the &lt;code&gt;UTF16CharacterStream&lt;/code&gt; makes the boundary quite stateful. The stream keeps track of its position in the buffer, which it increments after each consumed code unit. The scanner buffers a received code unit before going back to the scan method that requested the character. That method reads the buffered character and continues based on its value. This provides nice layering, but is fairly slow. Last fall, our intern Florian Sattler came up with an improved interface that keeps the benefits of the layering while providing much faster access to code units in the stream. A templatized function &lt;a href=&quot;https://cs.chromium.org/chromium/src/v8/src/parsing/scanner.h?rcl=d4096d05abfc992a150de884c25361917e06c6a9&amp;amp;l=72&quot;&gt;&lt;code&gt;AdvanceUntil&lt;/code&gt;&lt;/a&gt;, specialized for a specific scan helper, calls the helper for each character in the stream until the helper returns false. This essentially provides the scanner direct access to the underlying data without breaking abstractions. It actually simplifies the scan helper functions since they do not need to deal with &lt;code&gt;EndOfInput&lt;/code&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;https://v8.js.cn/_img/scanner/advanceuntil.svg&quot; intrinsicsize=&quot;600x371&quot; alt=&quot;&quot;&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;AdvanceUntil&lt;/code&gt; is especially useful to speed up scan functions that may need to consume large numbers of characters. We used it to speed up identifiers already shown earlier, but also strings&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn2&quot; id=&quot;fnref2&quot;&gt;[2]&lt;/a&gt;&lt;/sup&gt; and comments.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a class=&quot;bookmark&quot; href=&quot;#conclusion&quot; aria-hidden=&quot;true&quot;&gt;#&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The performance of scanning is the cornerstone of parser performance. We’ve tweaked our scanner to be as efficient as possible. This resulted in improvements across the board, improving the performance of single token scanning by roughly 1.4×, string scanning by 1.3×, multiline comment scanning by 2.1×, and identifier scanning by 1.2–1.5× depending on the identifier length.&lt;/p&gt;
&lt;p&gt;Our scanner can only do so much however. As a developer you can further improve parsing performance by increasing the information density of your programs. The easiest way to do so is by minifying your source code, stripping out unnecessary whitespace, and to avoid non-ASCII identifiers where possible. Ideally, these steps are automated as part of a build process, in which case you don’t have to worry about it when authoring code.&lt;/p&gt;
&lt;hr class=&quot;footnotes-sep&quot;&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;ol class=&quot;footnotes-list&quot;&gt;
&lt;li id=&quot;fn1&quot; class=&quot;footnote-item&quot;&gt;&lt;p&gt;&lt;code&gt;&amp;lt;!--&lt;/code&gt; is the start of an HTML comment, whereas &lt;code&gt;&amp;lt;!-&lt;/code&gt; scans as “less than”, “not”, “minus”. &lt;a href=&quot;#fnref1&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;fn2&quot; class=&quot;footnote-item&quot;&gt;&lt;p&gt;Strings and identifiers that cannot be encoded in Latin1 are currently more expensive since we first try to buffer them as Latin1, converting them to UTF-16 once we encounter a character that cannot be encoded in Latin1. &lt;a href=&quot;#fnref2&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content></entry></feed>